{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  프롬프트 엔지니어링 \n",
        "- 효과적인 프롬프트 템플릿 설계\n",
        "\n",
        "### **학습 목표:**  효과적인 프롬프트 템플릿의 기본 구조와 설계 원칙을 이해한다\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 환경 설정 및 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) Env 환경변수`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) 기본 라이브러리`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "from pprint import pprint\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(3) LLM 설정`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model='gpt-4.1-mini',\n",
        "    temperature=0.3,\n",
        "    top_p=0.9,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# **프롬프트 유형**\n",
        "\n",
        "- 종류: 질문형, 지시형, 대화형, 조건부, 예시 기반 등 \n",
        "- 이러한 프롬프트 유형들은 상황에 따라 조합하여 사용 가능\n",
        "- 목적에 맞는 적절한 유형을 선택하는 것이 중요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) 질문형 프롬프트 (Question Prompts)`\n",
        "   - 정보 추출에 효과적\n",
        "   - 구체적인 답변 유도 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('양자 컴퓨팅에 대해 알려드릴게요.\\n'\n",
            " '\\n'\n",
            " '양자 컴퓨팅(Quantum Computing)은 양자역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술입니다. 기존의 고전 컴퓨터가 '\n",
            " '비트(bit)를 사용해 0 또는 1의 값을 가지는 반면, 양자 컴퓨터는 양자 비트(큐비트, qubit)를 사용합니다. 큐비트는 0과 1의 '\n",
            " '상태를 동시에 가질 수 있는 중첩(superposition) 상태를 특징으로 하며, 이로 인해 병렬 계산 능력이 크게 향상됩니다.\\n'\n",
            " '\\n'\n",
            " '양자 컴퓨팅의 주요 개념은 다음과 같습니다:\\n'\n",
            " '\\n'\n",
            " '1. **큐비트(Qubit)**: 0과 1 두 상태를 동시에 가질 수 있는 양자 상태. 중첩과 얽힘(entanglement) 현상을 '\n",
            " '이용합니다.\\n'\n",
            " '2. **중첩(Superposition)**: 큐비트가 여러 상태를 동시에 표현할 수 있는 현상으로, 계산의 병렬성을 제공합니다.\\n'\n",
            " '3. **얽힘(Entanglement)**: 두 개 이상의 큐비트가 서로 강하게 연결되어 한 큐비트의 상태가 다른 큐비트의 상태에 '\n",
            " '즉각적으로 영향을 미치는 현상입니다.\\n'\n",
            " '4. **양자 게이트(Quantum Gate)**: 큐비트의 상태를 조작하는 연산자로, 고전 컴퓨터의 논리 게이트와 유사하지만 양자 '\n",
            " '상태를 변화시킵니다.\\n'\n",
            " '5. **양자 알고리즘**: 쇼어 알고리즘(Shor’s algorithm, 소인수분해), 그로버 알고리즘(Grover’s '\n",
            " 'algorithm, 검색 문제) 등 양자 컴퓨터에서 효율적으로 동작하는 알고리즘들이 있습니다.\\n'\n",
            " '\\n'\n",
            " '양자 컴퓨팅은 암호 해독, 최적화 문제, 분자 시뮬레이션, 머신러닝 등 다양한 분야에서 기존 컴퓨터보다 뛰어난 성능을 낼 가능성이 '\n",
            " '있습니다. 하지만 현재는 큐비트의 안정성, 오류율, 확장성 등의 기술적 한계로 인해 상용화 단계는 초기 단계에 머물러 있습니다.\\n'\n",
            " '\\n'\n",
            " '필요하시면 더 구체적인 내용이나 최신 연구 동향도 알려드릴 수 있습니다.')\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 단순 질문형\n",
        "question_prompt = PromptTemplate(\n",
        "    template=\"다음 주제에 대해 무엇을 알고 있나요?: {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "# LCEL chain 구성\n",
        "chain = question_prompt | llm\n",
        "\n",
        "# 질문\n",
        "topic = \"양자 컴퓨팅\"\n",
        "output = chain.invoke({\"topic\": topic})\n",
        "pprint(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('양자 컴퓨팅에 대해 알려드릴게요.\\n'\n",
            " '\\n'\n",
            " '양자 컴퓨팅(Quantum Computing)은 양자역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술입니다. 기존의 고전 컴퓨터가 '\n",
            " '비트(bit)를 사용해 0 또는 1의 상태로 정보를 표현하는 반면, 양자 컴퓨터는 큐비트(qubit)를 사용합니다. 큐비트는 0과 1의 '\n",
            " '중첩 상태(superposition)를 가질 수 있어, 동시에 여러 상태를 표현할 수 있습니다.\\n'\n",
            " '\\n'\n",
            " '주요 개념:\\n'\n",
            " '1. **큐비트(Qubit)**: 양자 컴퓨터의 기본 단위로, 0과 1의 상태를 동시에 가질 수 있는 중첩 상태를 특징으로 합니다.\\n'\n",
            " '2. **중첩(Superposition)**: 큐비트가 여러 상태를 동시에 가질 수 있는 현상으로, 병렬 계산 능력을 제공합니다.\\n'\n",
            " '3. **얽힘(Entanglement)**: 두 개 이상의 큐비트가 서로 강하게 연결되어 한 큐비트의 상태가 다른 큐비트의 상태에 '\n",
            " '즉각적으로 영향을 미치는 현상입니다. 이를 통해 복잡한 계산을 효율적으로 수행할 수 있습니다.\\n'\n",
            " '4. **양자 게이트(Quantum Gate)**: 큐비트의 상태를 조작하는 연산자로, 고전 컴퓨터의 논리 게이트와 유사하지만 양자 '\n",
            " '상태를 변화시키는 역할을 합니다.\\n'\n",
            " '\\n'\n",
            " '양자 컴퓨팅의 장점:\\n'\n",
            " '- 특정 문제(예: 소인수분해, 최적화 문제, 양자 시뮬레이션 등)를 고전 컴퓨터보다 훨씬 빠르게 해결할 수 있습니다.\\n'\n",
            " '- 암호 해독, 신약 개발, 재료 과학 등 다양한 분야에서 혁신적인 발전을 기대할 수 있습니다.\\n'\n",
            " '\\n'\n",
            " '현재 양자 컴퓨터는 아직 초기 단계에 있으며, 큐비트의 수와 안정성, 오류율 문제 등 기술적 도전 과제가 많습니다. 하지만 구글, '\n",
            " 'IBM, 마이크로소프트, 그리고 여러 연구 기관들이 활발히 연구 중이며, 점차 상용화 가능성이 높아지고 있습니다.\\n'\n",
            " '\\n'\n",
            " '필요하시면 더 구체적인 내용이나 최신 동향도 알려드릴 수 있습니다!')\n"
          ]
        }
      ],
      "source": [
        "### from_template 메소드를 사용한 방법\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from pprint import pprint\n",
        "\n",
        "# from_template을 사용한 PromptTemplate 생성\n",
        "question_template = \"다음 주제에 대해 무엇을 알고 있나요?: {topic}\"\n",
        "question_prompt = PromptTemplate.from_template(question_template)\n",
        "\n",
        "# LCEL chain 구성\n",
        "chain = question_prompt | llm\n",
        "\n",
        "# 질문 실행\n",
        "topic = \"양자 컴퓨팅\"\n",
        "output = chain.invoke({\"topic\": topic})\n",
        "pprint(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**[참고]** `from_template` 방식의 장점:\n",
        "- 코드가 더 간결해진다\n",
        "- 입력 변수를 수동으로 지정할 필요가 없다\n",
        "- 템플릿에서 사용된 변수를 자동으로 추출한다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('1. 양자 컴퓨팅은 양자역학의 원리를 기반으로 정보를 처리하는 기술이다.  \\n'\n",
            " '2. 전통적인 컴퓨팅과는 다른 방식으로 작동한다는 점이 특징이다.  \\n'\n",
            " '3. 텍스트는 양자 컴퓨팅의 정의와 그 차별성을 반복하여 강조하고 있다.')\n"
          ]
        }
      ],
      "source": [
        "# 분석 질문형 \n",
        "analysis_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 텍스트에서 주요 논점은 무엇인가요? 세 가지로 설명해주세요.\n",
        "\n",
        "    [텍스트]\n",
        "    {text}\n",
        "\n",
        "    [답변]\n",
        "    \"\"\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "chain = analysis_prompt | llm\n",
        "\n",
        "# 질문\n",
        "text = \"\"\"양자 컴퓨팅은 양자역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술이다. \n",
        "양자 컴퓨팅은 전통적인 컴퓨팅과는 다르게 양자역학의 원리를 이용하여 정보를 처리한다. \n",
        "양자 컴퓨팅은 양자역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술이다.\n",
        "\"\"\"\n",
        "\n",
        "output = chain.invoke({\"text\": text})\n",
        "pprint(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[실습 1]**\n",
        "\n",
        "- 앞의 예제를 from_template 메소드를 사용하는 방식으로 구현하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('1. 양자 컴퓨팅은 양자역학의 원리를 기반으로 정보를 처리하는 새로운 컴퓨팅 기술이다.  \\n'\n",
            " '2. 큐비트의 중첩과 얽힘 현상을 활용하여 병렬 연산이 가능하며, 특정 문제에서 기존 컴퓨터보다 훨씬 빠른 계산 속도를 제공한다.  \\n'\n",
            " '3. 신약 개발, 신소재 설계, 금융 모델링 등 복잡한 시뮬레이션이 필요한 분야에 혁신적인 변화를 가져올 잠재력을 가지고 있다.')\n"
          ]
        }
      ],
      "source": [
        "# 여기에 코드를 작성하세요.\n",
        "analysis_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"다음 텍스트에서 주요 논점은 무엇인가요? 세 가지로 설명해주세요. \n",
        "\n",
        "    [텍스트] \n",
        "    {text} \n",
        "\n",
        "    [답변] \n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "chain = analysis_prompt | llm\n",
        "\n",
        "text = \"\"\"양자 컴퓨팅은 양자역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술이다.\n",
        "양자 컴퓨팅은 전통적인 컴퓨팅과는 다르게 큐비트(qubit)의 중첩과 얽힘 현상을 활용하여\n",
        "병렬 연산을 수행할 수 있어, 특정 문제에 대해 기존 컴퓨터보다 월등히 빠른 계산 속도를 보인다.\n",
        "이는 신약 개발, 신소재 설계, 금융 모델링 등 복잡한 시뮬레이션이 필요한 분야에 혁신을 가져올 잠재력을 가진다.\n",
        "\"\"\"\n",
        "\n",
        "output = chain.invoke({\"text\": text})\n",
        "\n",
        "pprint(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) 지시형 프롬프트 (Instruction Prompts)`\n",
        "   - 명확한 작업 수행 지시\n",
        "   - 단계별 처리 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 랭퓨즈 핸들러 추가\n",
        "from langfuse.langchain import CallbackHandler\n",
        "langfuse_handler = CallbackHandler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'양자 컴퓨팅은 양자 역학의 원리를 이용하여 정보를 처리하는 컴퓨팅 기술입니다.'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "# 작업 지시형\n",
        "task_prompt = PromptTemplate(\n",
        "    template=\"다음 텍스트를 한국어로 번역하세요:\\n\\n<텍스트>\\n{text}\\n</텍스트>\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "chain = task_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 질문\n",
        "text = \"Quantum computing is a computing technology that uses the principles of quantum mechanics to process information.\"\n",
        "### 랭퓨즈 핸들러 추가\n",
        "output = chain.invoke({\"text\": text}, config={\"callbacks\": [langfuse_handler]})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "ename": "ResponseError",
          "evalue": "model \"qwen3:4b\" not found, try pulling it first (status code: 404)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 질문\u001b[39;00m\n\u001b[32m     22\u001b[39m text = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m양자 컴퓨팅은 양자역학의 원리를 바탕으로 데이터를 처리하는 새로운 형태의 계산 방식이다. \u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m기존의 고전적 컴퓨터는 0과 1로 이루어진 이진법(bit)을 사용하여 데이터를 처리하지만, \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33m이를 통해 병렬 계산과 같은 고급 기능이 가능하다.\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33m\"\"\"\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m output = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlangfuse_handler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m pprint(output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3082\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3080\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3081\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3082\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:393\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    388\u001b[39m     **kwargs: Any,\n\u001b[32m    389\u001b[39m ) -> BaseMessage:\n\u001b[32m    390\u001b[39m     config = ensure_config(config)\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    392\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    403\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1019\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1016\u001b[39m     **kwargs: Any,\n\u001b[32m   1017\u001b[39m ) -> LLMResult:\n\u001b[32m   1018\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:837\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    843\u001b[39m         )\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    845\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1085\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1083\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:822\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    816\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    817\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m     **kwargs: Any,\n\u001b[32m    821\u001b[39m ) -> ChatResult:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    825\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m    826\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    827\u001b[39m         message=AIMessage(\n\u001b[32m    828\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m    833\u001b[39m         generation_info=generation_info,\n\u001b[32m    834\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:757\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    749\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    750\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    754\u001b[39m     **kwargs: Any,\n\u001b[32m    755\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    756\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:844\u001b[39m, in \u001b[36mChatOllama._iterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iterate_over_stream\u001b[39m(\n\u001b[32m    838\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    839\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m    840\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    841\u001b[39m     **kwargs: Any,\n\u001b[32m    842\u001b[39m ) -> Iterator[ChatGenerationChunk]:\n\u001b[32m    843\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    850\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:743\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.chat(**chat_params)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Modu_LLM\\LLM_faq_chatbot_tutorial\\faq_chatbot\\.venv\\Lib\\site-packages\\ollama\\_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m   e.response.read()\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.iter_lines():\n\u001b[32m    173\u001b[39m   part = json.loads(line)\n",
            "\u001b[31mResponseError\u001b[39m: model \"qwen3:4b\" not found, try pulling it first (status code: 404)"
          ]
        }
      ],
      "source": [
        "# 단계별 지시형\n",
        "step_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 텍스트에 대해서 작업을 순서대로 수행하세요:\n",
        "\n",
        "    [텍스트]\n",
        "    {text}\n",
        "\n",
        "    [작업 순서]\n",
        "    1. 텍스트를 1문장으로 요약\n",
        "    2. 핵심 키워드 3개 추출\n",
        "    3. 감정 분석 수행(긍정/부정/중립)\n",
        "\n",
        "    [작업 결과]\n",
        "    \"\"\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "chain = step_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 질문\n",
        "text = \"\"\"\n",
        "양자 컴퓨팅은 양자역학의 원리를 바탕으로 데이터를 처리하는 새로운 형태의 계산 방식이다. \n",
        "기존의 고전적 컴퓨터는 0과 1로 이루어진 이진법(bit)을 사용하여 데이터를 처리하지만, \n",
        "양자 컴퓨터는 양자 비트(큐비트, qubit)를 사용하여 훨씬 더 복잡하고 빠른 계산을 수행할 수 있다. \n",
        "\n",
        "큐비트는 동시에 0과 1의 상태를 가질 수 있는 양자 중첩(superposition) 상태를 활용하며, \n",
        "이를 통해 병렬 계산과 같은 고급 기능이 가능하다.\n",
        "\"\"\" \n",
        "\n",
        "output = chain.invoke({\"text\": text}, config={\"callbacks\": [langfuse_handler]})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[실습 2]**\n",
        "\n",
        "- 두 개의 문장을 입력받아서, 두 문장의 맥락이 일치하는지 여부를 비교 분석하는 체인을 구성하세요.\n",
        "- PromptTemplate를 사용하고, 두 문장을 입력받을 수 있도록 합니다. \n",
        "- 단계별 지시형 프롬프트로 작성합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('[작업 결과]\\n'\n",
            " '\\n'\n",
            " '1. 두 문장의 맥락 파악  \\n'\n",
            " '- 첫 번째 문장: \"Splunk는 빅데이터를 위한 상용 솔루션이다.\"  \\n'\n",
            " '  → Splunk라는 특정 제품이 빅데이터 처리에 사용되는 상용 소프트웨어임을 설명하고 있음.  \\n'\n",
            " '- 두 번째 문장: \"최근 외산 솔루션을 이용하는 대기업이 증가하면서 국산 솔루션의 입지가 줄어들고 있다.\"  \\n'\n",
            " '  → 최근 대기업들이 외국산 소프트웨어 솔루션을 더 많이 사용하게 되어, 국내에서 개발된 소프트웨어 솔루션의 시장 점유율이나 영향력이 '\n",
            " '감소하고 있음을 설명하고 있음.\\n'\n",
            " '\\n'\n",
            " '2. 두 문장의 맥락 비교  \\n'\n",
            " '- 첫 문장은 특정 솔루션(Splunk)에 대한 소개에 초점이 맞춰져 있음.  \\n'\n",
            " '- 두 번째 문장은 시장 동향과 관련하여 외산 솔루션의 증가와 국산 솔루션의 감소라는 변화에 대해 설명하고 있음.  \\n'\n",
            " '- 두 문장 모두 소프트웨어 솔루션과 관련되어 있으나, 첫 문장은 제품 설명, 두 번째 문장은 시장 상황을 다루고 있어 직접적인 내용 '\n",
            " '연결은 약함.\\n'\n",
            " '\\n'\n",
            " '3. 맥락 일치 여부 파악  \\n'\n",
            " '- 두 문장은 모두 소프트웨어 솔루션과 관련된 내용을 다루고 있으나, 첫 문장은 특정 솔루션 소개, 두 번째 문장은 시장 점유율 변화라는 '\n",
            " '다른 관점에서 접근하고 있어 맥락이 완전히 일치한다고 보기 어렵다.  \\n'\n",
            " '- 다만, 두 문장 모두 외산 솔루션과 관련된 내용이 포함되어 있어 넓은 의미에서는 연관성이 있다고 판단할 수 있음.\\n'\n",
            " '\\n'\n",
            " '종합적으로, 두 문장은 주제 영역(소프트웨어 솔루션)에서는 관련성이 있으나, 구체적인 내용과 초점이 다르므로 맥락이 완전히 일치하지는 '\n",
            " '않는다.')\n"
          ]
        }
      ],
      "source": [
        "# 여기에 코드를 작성하세요.\n",
        "step_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 텍스트에 대해서 작업을 순서대로 수행하세요:\n",
        "\n",
        "    [텍스트]\n",
        "    {text1}\n",
        "    {text2}\n",
        "\n",
        "    [작업 순서]\n",
        "    1.  두 문장의 맥락을 파악\n",
        "    2. 두 문장의 맥락을 비교\n",
        "    3. 맥락이 일치하는지 여부 파악\n",
        "\n",
        "    [작업 결과]\n",
        "    \"\"\",\n",
        "    input_variables=[\"text1\", \"text2\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "chain = \n",
        "| llm | StrOutputParser()\n",
        "\n",
        "# 질문\n",
        "text1 = \"\"\"\n",
        "Splunk는 빅데이터를 위한 상용 솔루션이다.\n",
        "\"\"\" \n",
        "\n",
        "text2 = \"\"\"\n",
        "최근 외산 솔루션을 이용하는 대기업이 증가하면서 국산 솔루션의 입지가 줄어들고 있다.\n",
        "\"\"\"\n",
        "\n",
        "output = chain.invoke({\"text1\": text1, \"text2\": text2}, config={\"callbacks\": [langfuse_handler]})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(3) 대화형 프롬프트 (Conversational Prompts)`\n",
        "   - 자연스러운 상호작용\n",
        "   - 문맥 유지 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'안녕하세요! 불편을 드려 죄송합니다. 배송 문제에 대해 자세히 말씀해 주시면 신속히 도와드리겠습니다. 어떤 문제가 있으신가요?'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ChatPromptTemplate 객체를 직접 생성 (메시지 리스트, 입력 변수 리스트)\n",
        "chat_prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        (\"system\", \"당신은 친절한 고객 서비스 담당자입니다.\"),\n",
        "        (\"human\", \"{customer_message}\")\n",
        "    ],\n",
        "    input_variables=[\"customer_message\"]\n",
        ")\n",
        "\n",
        "# LCEL chain 구성\n",
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 질문 실행\n",
        "customer_message = \"안녕하세요. 제품 배송 문제로 연락드렸어요.\"\n",
        "output = chain.invoke({\"customer_message\": customer_message})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'안녕하세요! 불편을 드려 죄송합니다. 배송 문제에 대해 자세히 말씀해 주시면 빠르게 도와드리겠습니다. 어떤 문제가 있으신가요?'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# from_messages 메소드를 사용한 ChatPromptTemplate 생성\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    {\"role\":\"system\", \"content\":\"당신은 친절한 고객 서비스 담당자입니다.\"},\n",
        "    {\"role\":\"user\", \"content\":\"{customer_message}\"},\n",
        "])\n",
        "\n",
        "# LCEL\n",
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 질문\n",
        "customer_message = \"안녕하세요. 제품 배송 문제로 연락드렸어요.\"\n",
        "output = chain.invoke({\"customer_message\": customer_message},config={\"callbacks\": [langfuse_handler]})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'안녕하세요! 불편을 드려 죄송합니다. 배송 문제에 대해 자세히 말씀해 주시면 빠르게 도와드리겠습니다. 어떤 문제가 있으신가요?'\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "\n",
        "# 메시지 템플릿 사용\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\n",
        "        \"당신은 친절한 고객 서비스 담당자입니다.\"\n",
        "    ),\n",
        "    HumanMessagePromptTemplate.from_template(\n",
        "        \"{customer_message}\"\n",
        "    )\n",
        "])\n",
        "\n",
        "# LCEL\n",
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 질문\n",
        "customer_message = \"안녕하세요. 제품 배송 문제로 연락드렸어요.\"\n",
        "output = chain.invoke({\"customer_message\": customer_message})\n",
        "pprint(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[실습 3]**\n",
        "\n",
        "- 상품 리뷰를 분석하는 AI 체인을 대화형 프롬프트로 구성합니다. \n",
        "- 메시지 템플릿을 사용하여 메시지 역할을 구분합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예시 리뷰\n",
        "reviews = [\n",
        "    \"이 블루투스 이어폰 정말 만족스러워요! 음질도 좋고 배터리도 오래가요. 다만 케이스가 좀 큰 감이 있네요.\",\n",
        "    \"배송은 빨랐는데 제품 품질이 기대에 못 미쳐요. 터치감이 둔하고 연결이 자주 끊깁니다. 가성비 생각하면 그냥 쓸만하네요.\",\n",
        "    \"가격대비 괜찮은 것 같아요. 디자인도 깔끔하고 기본적인 기능은 다 갖췄네요. 추천합니다!\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 리뷰 1 분석 결과 ===\n",
            "리뷰 작성자는 음질과 배터리 수명에 만족하며 긍정적인 평가를 했으나, 케이스 크기에 대한 약간의 아쉬움을 표현했습니다.\n",
            "\n",
            "점수 : 8점\n",
            "\n",
            "=== 리뷰 2 분석 결과 ===\n",
            "리뷰는 배송이 빨랐다는 긍정적인 부분이 있으나, 제품 품질과 성능에 대한 불만이 주를 이루어 전반적으로 부정적인 감정이 강하게 나타납니다.\n",
            "\n",
            "점수 : 3점\n",
            "\n",
            "=== 리뷰 3 분석 결과 ===\n",
            "리뷰에서 가격 대비 만족스럽고 디자인과 기능 모두 긍정적으로 평가하며 추천 의사를 밝히고 있어 긍정적인 감정으로 판단됩니다.\n",
            "\n",
            "점수 : 9점\n"
          ]
        }
      ],
      "source": [
        "# 여기에 코드를 작성하세요.\n",
        "\n",
        "review_prompt = ChatPromptTemplate.from_messages([\n",
        "    {\"role\":\"system\", \"content\":\"\"\"\n",
        "     당신은 제품 리뷰 분석가입니다. \n",
        "     리뷰를 분석하여 긍정적인지 부정적인지 판단합니다.\n",
        "     \"\"\"},\n",
        "    {\"role\":\"user\", \"content\":\"\"\"다음 리뷰의 감정을 분석합니다.  {review}\n",
        "    판단한 근거를 1문장으로 작성해주세요 \n",
        "     작성자의 긍정적인 감정을 0~10점으로 점수를 부여해주세요.\n",
        "     점수 부여 시,  한줄을 띄고 \"점수 : n점\" 형식으로만 작성해주세요\n",
        "     \"\"\"}])\n",
        "\n",
        "review_chain= review_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 각 리뷰 분석 실행\n",
        "for idx, review in enumerate(reviews, 1):\n",
        "    print(f\"\\n=== 리뷰 {idx} 분석 결과 ===\")\n",
        "    result = review_chain.invoke({\"review\": review},config={\"callbacks\": [langfuse_handler]}) \n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(4) 예시 기반 프롬프트 (Few-Shot Prompts)`\n",
        "   - 원하는 출력 형식 명확화\n",
        "   - 모델의 이해도 향상"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\skssk\\AppData\\Local\\Temp\\ipykernel_25388\\3970753415.py:16: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chain = few_shot_prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'양자 컴퓨팅: 양자역학을 이용해 정보를 처리하는 혁신적 기술로, 빠른 계산 속도를 자랑한다.'\n"
          ]
        }
      ],
      "source": [
        "few_shot_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음은 텍스트를 요약하는 예시입니다:\n",
        "\n",
        "원문: {example_input}\n",
        "요약: {example_output}\n",
        "\n",
        "이제 다음 텍스트를 같은 방식으로 50자 이내로 요약해주세요:\n",
        "원문: {input_text}\n",
        "요약:\n",
        "\"\"\",\n",
        "    input_variables=[\"example_input\", \"example_output\", \"input_text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "### 모델을 gpt-4.0-mini로 변경 (이전 모델은 요약시 요약: 을 붙이는 경향이 있음)\n",
        "chain = few_shot_prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
        "\n",
        "# 예시 텍스트 \n",
        "example_input = \"\"\"인공지능(AI)은 인간의 학습능력, 추론능력, 지각능력, 자연언어의 이해능력 등을 \n",
        "컴퓨터 프로그램으로 실현한 기술이다. 인공지능은 딥러닝, 기계학습 등 다양한 기술을 포함하며, \n",
        "최근에는 자율주행, 의료진단, 언어번역 등 다양한 분야에서 활용되고 있다.\"\"\"\n",
        "\n",
        "example_output = \"인공지능: 인간의 학습능력, 추론능력, 지각능력 등을 컴퓨터 프로그램으로 실현한 기술\"\n",
        "\n",
        "# 입력 텍스트 \n",
        "input_text = \"\"\"양자 컴퓨팅은 양자역학의 원리를 활용하여 정보를 처리하는 혁신적인 컴퓨팅 기술이다. \n",
        "기존의 디지털 컴퓨터가 0과 1의 이진법을 사용하는 것과 달리, 양자 컴퓨터는 중첩 상태를 활용하여 \n",
        "동시에 여러 계산을 수행할 수 있다. 이러한 특성으로 인해 특정 문제에서는 기존 컴퓨터보다 \n",
        "월등히 빠른 처리 속도를 보여준다. 현재는 아직 초기 단계지만, 암호화, 신약 개발, 기후 모델링 등 \n",
        "다양한 분야에서 혁신적인 발전이 기대된다.\"\"\"\n",
        "\n",
        "# 체인 실행\n",
        "output = chain.invoke({\n",
        "    \"example_input\": example_input, \n",
        "    \"example_output\": example_output, \n",
        "    \"input_text\": input_text\n",
        "})\n",
        "pprint(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **[실습 4]**\n",
        "\n",
        "- [실습 3]의 상품 리뷰 분석 시스템의 입출력 형식을 예시로 추가해서 프롬프트를 작성합니다.\n",
        "- 체인을 실해하여 테스트합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 리뷰 1 분석 결과 ===\n",
            "점수: 8점 - 음질과 배터리에 대해 긍정적이나 케이스 크기에 부정적임.\n",
            "\n",
            "=== 리뷰 2 분석 결과 ===\n",
            "점수 : 5점 - 배송은 빠르나 품질이 저조하고 연결 문제 발생. 가성비는 괜찮음.\n",
            "\n",
            "=== 리뷰 3 분석 결과 ===\n",
            "점수 : 8점 - 가격대비 좋고 깔끔한 디자인, 기본 기능 완비로 추천함.\n"
          ]
        }
      ],
      "source": [
        "# 여기에 코드를 작성하세요.\n",
        "review_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 예시와 같은 방식으로 리뷰의 감정을 분석해주세요:\n",
        "\n",
        "원문: {example_input}\n",
        "요약: {example_output}\n",
        "\n",
        "이제 다음 리뷰를 같은 방식으로 감정을 분석해주세요:\n",
        "원문: {input_text}\n",
        "요약:\n",
        "\"\"\",\n",
        "    input_variables=[\"example_input\", \"example_output\", \"input_text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "### 모델을 gpt-4.0-mini로 변경 (이전 모델은 요약시 요약: 을 붙이는 경향이 있음)\n",
        "chain = few_shot_prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
        "\n",
        "# 예시 텍스트 \n",
        "example_input = \"\"\"이 제품은 가성비가 좋습니다. \n",
        "비록 플라스틱 하우징이기 때문에 고급스럽지는 않지만 플라스틱 키보드보다 치고 \n",
        "좋은 타건감과 스테빌라이저도 잘 잡은 모습을 보여줍니다.\n",
        "\"\"\"\n",
        "\n",
        "example_output = \"점수 : 7점 - 플라스틱 하우징에 대하여 부정적이지만 타건감과 스테빌라이저에 대하여 긍정적임\"\n",
        "\n",
        "\n",
        "# 체인 실행\n",
        "for idx, review in enumerate(reviews, 1):\n",
        "    print(f\"\\n=== 리뷰 {idx} 분석 결과 ===\")\n",
        "    result = chain.invoke({\n",
        "        \"example_input\": example_input, \n",
        "        \"example_output\": example_output, \n",
        "        \"input_text\": review\n",
        "    })\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 예시 프롬프트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "분석:\n",
            "- 감정: 긍정적\n",
            "- 장점: 예쁜 디자인, 부드러운 작동, 전반적인 만족도\n",
            "- 단점: 가끔 연결 끊김 현상\n",
            "- 종합: 디자인과 성능에 만족하지만 연결 안정성 개선 필요\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Few-Shot 예시를 포함한 시스템 메시지\n",
        "system_message = \"\"\"당신은 상품 리뷰 분석 전문가입니다. 리뷰를 분석하여 아래 형식으로 출력합니다:\n",
        "\n",
        "예시 1:\n",
        "리뷰: \"이 노트북 정말 가볍고 좋아요! 배터리도 오래가고 화면도 선명해요. 다만 가격이 조금 비싸네요.\"\n",
        "분석:\n",
        "- 감정: 긍정적\n",
        "- 장점: 가벼움, 배터리 수명, 화면 품질\n",
        "- 단점: 높은 가격\n",
        "- 종합: 전반적으로 만족, 가격 대비 가치 고려 필요\n",
        "\n",
        "예시 2:\n",
        "리뷰: \"배송이 늦어져서 실망했어요. 제품 자체는 나쁘지 않은데 AS가 불편해요.\"\n",
        "분석:\n",
        "- 감정: 부정적\n",
        "- 장점: 제품 품질 양호\n",
        "- 단점: 늦은 배송, AS 서비스 불편\n",
        "- 종합: 서비스 개선 필요\n",
        "\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿 구성\n",
        "review_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(content=system_message),\n",
        "    HumanMessagePromptTemplate.from_template(\"다음 리뷰를 분석해주세요:\\n리뷰: {review}\")\n",
        "])\n",
        "\n",
        "# 체인 구성\n",
        "review_chain = review_prompt | llm | StrOutputParser()\n",
        "\n",
        "# 테스트\n",
        "test_review = \"이 무선 마우스 디자인이 예쁘고 작동도 부드러워요. 근데 가끔 연결이 끊기는게 아쉽네요. 전체적으로는 만족합니다.\"\n",
        "result = review_chain.invoke({\"review\": test_review})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(5) 조건부 프롬프트 (Conditional Prompts)`\n",
        "   - 상황별 다른 처리\n",
        "   - 유연한 응답 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 조건부 프롬프트 템플릿 정의 (입력 텍스트에 따라 작업 유형을 지정)\n",
        "conditional_prompt = PromptTemplate(\n",
        "    template=\"\"\"입력 텍스트: {text}\n",
        "\n",
        "주어진 텍스트가 질문인 경우: 명확한 답변을 제공\n",
        "주어진 텍스트가 진술문인 경우: 진술문의 사실 여부를 검증\n",
        "주어진 텍스트가 요청사항인 경우: 수행 방법을 단계별로 설명\n",
        "\n",
        "응답은 다음 형식을 따라주세요:\n",
        "유형: [질문/진술문/요청사항]\n",
        "내용: [상세 응답]\"\"\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# LCEL 체인 구성\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "chain = conditional_prompt | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유형: 질문  \n",
            "내용: 인공지능이 인간의 일자리를 모두 대체할 가능성은 매우 낮습니다. 인공지능은 반복적이고 규칙 기반의 작업을 자동화하는 데 뛰어나지만, 창의성, 감정적 지능, 복잡한 의사결정 등 인간 고유의 능력을 완전히 대체하기는 어렵습니다. 또한, 인공지능의 발전은 새로운 일자리와 산업을 창출할 가능성도 큽니다. 따라서 인공지능은 일부 직업을 변화시키거나 대체할 수 있지만, 모든 일자리를 대체하는 것은 현실적으로 불가능하며, 인간과 인공지능이 협력하는 형태로 일자리 환경이 변화할 것으로 예상됩니다.\n"
          ]
        }
      ],
      "source": [
        "# 질문형 테스트\n",
        "response = chain.invoke({\n",
        "    \"text\": \"인공지능은 인간의 일자리를 모두 대체하게 될까요?\",\n",
        "})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유형: 진술문  \n",
            "내용: \"양자컴퓨터는 현재 모든 암호화 시스템을 무력화할 수 있다\"는 진술은 사실이 아닙니다. 현재 상용화된 양자컴퓨터는 매우 제한된 규모이며, 기존의 대부분 암호화 시스템을 무력화할 만큼의 성능을 갖추지 못했습니다. 다만, 이론적으로 충분히 발전한 양자컴퓨터는 일부 암호화 알고리즘(예: RSA, ECC)을 깨뜨릴 수 있는 잠재력을 가지고 있으나, 이를 대비한 양자내성암호(포스트 양자 암호) 연구도 활발히 진행 중입니다. 따라서 현재 시점에서 모든 암호화 시스템이 무력화되었다고 보기는 어렵습니다.\n"
          ]
        }
      ],
      "source": [
        "# 진술문 테스트\n",
        "response = chain.invoke({\n",
        "    \"text\": \"양자컴퓨터는 현재 모든 암호화 시스템을 무력화할 수 있다.\"\n",
        "})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "유형: 요청사항  \n",
            "내용: 파이썬으로 간단한 웹 스크래퍼를 만드는 방법을 단계별로 설명드리겠습니다.\n",
            "\n",
            "1. 필요한 라이브러리 설치  \n",
            "   - `requests`: 웹 페이지의 HTML을 가져오기 위해 사용  \n",
            "   - `BeautifulSoup`: HTML을 파싱하여 원하는 데이터를 추출하기 위해 사용  \n",
            "   ```bash\n",
            "   pip install requests beautifulsoup4\n",
            "   ```\n",
            "\n",
            "2. 웹 페이지 요청 및 HTML 가져오기  \n",
            "   ```python\n",
            "   import requests\n",
            "\n",
            "   url = 'https://example.com'  # 스크래핑할 웹 페이지 URL\n",
            "   response = requests.get(url)\n",
            "   html = response.text\n",
            "   ```\n",
            "\n",
            "3. HTML 파싱 및 데이터 추출  \n",
            "   ```python\n",
            "   from bs4 import BeautifulSoup\n",
            "\n",
            "   soup = BeautifulSoup(html, 'html.parser')\n",
            "   # 예: 모든 <a> 태그의 텍스트와 링크 추출\n",
            "   for a_tag in soup.find_all('a'):\n",
            "       print(a_tag.text, a_tag.get('href'))\n",
            "   ```\n",
            "\n",
            "4. 결과 활용  \n",
            "   - 추출한 데이터를 파일로 저장하거나, 원하는 형태로 가공할 수 있습니다.\n",
            "\n",
            "5. 주의사항  \n",
            "   - 웹사이트의 robots.txt 파일을 확인하여 스크래핑이 허용되는지 확인하세요.  \n",
            "   - 과도한 요청은 서버에 부담을 줄 수 있으니 적절한 딜레이를 두세요.\n",
            "\n",
            "이 과정을 통해 간단한 웹 스크래퍼를 만들 수 있습니다. 필요에 따라 더 복잡한 기능도 추가 가능합니다.\n"
          ]
        }
      ],
      "source": [
        "# 요청사항 테스트\n",
        "response = chain.invoke({\n",
        "        \"text\": \"파이썬으로 간단한 웹 스크래퍼를 만들고 싶습니다.\"\n",
        "})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "# **프롬프트 엔지니어링 개념**\n",
        "\n",
        "1. **개념**:\n",
        "    - AI 모델에게 효과적인 지시를 제공하여 원하는 결과를 얻어내는 기술\n",
        "    - 입력(프롬프트)을 최적화하여 출력의 품질을 향상하는 방법 \n",
        "\n",
        "2. **원칙**:\n",
        "\n",
        "    1. **명확성(Clarity)**\n",
        "        - 모호하지 않은 명확한 지시사항 제공\n",
        "        - 구체적인 요구사항과 제약조건 명시\n",
        "        - 예시: \"5개의 짧은 문장으로 요약해주세요\" vs \"요약해주세요\"\n",
        "\n",
        "    1. **맥락성(Context)**\n",
        "        - 관련 배경 정보 제공\n",
        "        - 목적과 의도 명시\n",
        "        - 대상 독자나 사용 환경 설명\n",
        "\n",
        "    1. **구조화(Structure)**\n",
        "        - 체계적인 형식 사용\n",
        "        - 단계별 지시사항 제공\n",
        "        - 원하는 출력 형식 명시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. **명확성(Clarity)**\n",
        "\n",
        "- **프롬프트의 명확성**은 AI 모델과의 효과적인 소통을 위한 핵심 요소\n",
        "\n",
        "- 불필요한 내용을 제외하고 **핵심 요구사항**에만 집중하여 작성\n",
        "\n",
        "- 원하는 결과물에 대해 **구체적이고 정확한 지시**를 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('- 인공지능은 컴퓨터가 인간처럼 학습하고 문제를 해결하는 기술을 의미합니다.  \\n'\n",
            " '- 머신러닝(데이터로부터 학습하는 알고리즘)은 인공지능의 핵심 분야 중 하나입니다.  \\n'\n",
            " '- 인공지능은 의료, 금융, 자율주행 등 다양한 산업에서 혁신을 이끌고 있습니다.')\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 명확한 지시사항이 포함된 프롬프트 템플릿\n",
        "clear_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"\"\"\n",
        "    주제: {topic}\n",
        "    \n",
        "    다음 기준을 반드시 준수하여 설명하시오:\n",
        "    1. 정확히 3문장으로 작성할 것 (Bullet point 사용하여 구분)\n",
        "    2. 각 문장은 20단어 이내로 작성할 것\n",
        "    3. 전문 용어는 괄호 안에 간단한 설명을 포함할 것\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# LCEL 체인\n",
        "clear_chain = clear_prompt | llm \n",
        "\n",
        "# 테스트\n",
        "result = clear_chain.invoke({\"topic\": \"인공지능\"})\n",
        "pprint(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. **맥락성(Context)**\n",
        "\n",
        "- **맥락 제공**은 AI가 작업의 배경과 목적을 이해하는데 필수적인 요소\n",
        "\n",
        "- 프롬프트에 **배경 정보**, **목적**, **대상 환경**을 명확히 포함\n",
        "\n",
        "- 적절한 맥락 제공은 AI의 **출력 품질**과 **정확도**를 크게 향상"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "맥락이 부족한 프롬프트의 결과\n",
            "('아이폰에 카카오톡을 설치하는 방법을 안내해드릴게요.\\n'\n",
            " '\\n'\n",
            " '1. **앱스토어 열기**  \\n'\n",
            " '   아이폰에서 홈 화면에 있는 **App Store** 아이콘을 탭하여 앱스토어를 실행합니다.\\n'\n",
            " '\\n'\n",
            " '2. **검색하기**  \\n'\n",
            " '   하단의 돋보기 모양 아이콘(검색)을 탭한 후, 검색창에 **\"카카오톡\"**을 입력하고 검색합니다.\\n'\n",
            " '\\n'\n",
            " '3. **카카오톡 선택**  \\n'\n",
            " '   검색 결과에서 **카카오톡(KakaoTalk)** 앱을 찾아 탭합니다. 개발사는 \"Kakao Corp.\"입니다.\\n'\n",
            " '\\n'\n",
            " '4. **앱 설치하기**  \\n'\n",
            " '   **받기** 또는 클라우드 모양 아이콘을 탭하여 앱을 다운로드하고 설치합니다. Apple ID 비밀번호를 묻거나 Face '\n",
            " 'ID/Touch ID 인증을 요청할 수 있습니다.\\n'\n",
            " '\\n'\n",
            " '5. **설치 완료 후 열기**  \\n'\n",
            " '   설치가 완료되면 **열기** 버튼을 눌러 카카오톡을 실행하거나, 홈 화면에서 카카오톡 아이콘을 찾아 실행합니다.\\n'\n",
            " '\\n'\n",
            " '6. **회원가입 또는 로그인**  \\n'\n",
            " '   처음 사용하는 경우 회원가입을 하시고, 기존 계정이 있다면 로그인하시면 됩니다.\\n'\n",
            " '\\n'\n",
            " '필요하시면 추가로 카카오톡 사용법도 알려드릴 수 있습니다!')\n",
            "----------------------------------------------------------------------------------------------------\n",
            "맥락이 풍부한 프롬프트의 결과\n",
            "('안녕하세요! 아이폰에 카카오톡을 설치하는 방법을 아주 쉽게, 차근차근 알려드릴게요. 스마트폰을 처음 사용하시는 분들도 따라 하실 수 '\n",
            " '있도록 아주 쉽게 설명드릴게요.\\n'\n",
            " '\\n'\n",
            " '---\\n'\n",
            " '\\n'\n",
            " '### 아이폰에 카카오톡 설치하는 방법\\n'\n",
            " '\\n'\n",
            " '#### 1단계: 아이폰에서 ‘앱스토어’ 찾기  \\n'\n",
            " '- 아이폰 바탕화면에서 **파란색 글자 A 모양 아이콘**을 찾아서 눌러주세요.  \\n'\n",
            " '- 이 아이콘이 ‘앱스토어’입니다. 앱을 다운로드하는 곳이에요.\\n'\n",
            " '\\n'\n",
            " '#### 2단계: 앱스토어에서 ‘카카오톡’ 검색하기  \\n'\n",
            " '- 앱스토어가 열리면, 아래쪽에 돋보기 모양(🔍)이 있어요. 그걸 눌러주세요.  \\n'\n",
            " '- 위에 흰색 검색창이 나오면, 손가락으로 눌러서 ‘카카오톡’이라고 써주세요.  \\n'\n",
            " '- 키보드에서 ‘검색’ 버튼을 눌러주세요.\\n'\n",
            " '\\n'\n",
            " '#### 3단계: 카카오톡 앱 찾기  \\n'\n",
            " '- 검색 결과 중에서 ‘카카오톡’이라는 이름과 노란색 말풍선 모양 아이콘을 찾아주세요.  \\n'\n",
            " '- 맞는 앱이 보이면, 오른쪽에 있는 ‘받기’ 또는 구름 모양 아이콘을 눌러주세요.\\n'\n",
            " '\\n'\n",
            " '#### 4단계: 앱 다운로드 및 설치  \\n'\n",
            " '- ‘받기’를 누르면, 아이폰이 앱을 다운로드하고 설치하기 시작해요.  \\n'\n",
            " '- 설치가 끝나면 ‘열기’라는 버튼이 생겨요. 그걸 눌러주세요.\\n'\n",
            " '\\n'\n",
            " '#### 5단계: 카카오톡 실행 및 회원가입  \\n'\n",
            " '- 카카오톡이 열리면, 안내에 따라 휴대폰 번호를 입력하고 회원가입을 하시면 됩니다.  \\n'\n",
            " '- 가족이나 강사님께 도움을 받아 천천히 진행해 보세요.\\n'\n",
            " '\\n'\n",
            " '---\\n'\n",
            " '\\n'\n",
            " '### 참고  \\n'\n",
            " '- 아이폰에 앱을 설치하려면, 애플 아이디(Apple ID)라는 계정이 필요해요.  \\n'\n",
            " '- 만약 애플 아이디가 없으면, 강사님이나 가족분께 도움을 요청하세요.  \\n'\n",
            " '- 설치 중에 ‘암호 입력’이나 ‘지문 인식’ 요청이 나오면, 알려주시는 분과 함께 차근차근 진행하세요.\\n'\n",
            " '\\n'\n",
            " '---\\n'\n",
            " '\\n'\n",
            " '### 예시  \\n'\n",
            " '- “앱스토어” 아이콘은 이렇게 생겼어요: 파란색 바탕에 흰색 A 모양  \\n'\n",
            " '- “카카오톡” 아이콘은 이렇게 생겼어요: 노란색 바탕에 검은 말풍선 모양  \\n'\n",
            " '\\n'\n",
            " '---\\n'\n",
            " '\\n'\n",
            " '천천히 따라 하시면 어렵지 않아요! 궁금한 점 있으면 언제든지 물어보세요. 응원합니다! 😊')\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# 맥락이 부족한 프롬프트의 예\n",
        "bad_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "당신은 친절한 AI 어시스턴트입니다. 사용자의 질문에 답변해주세요.\n",
        "사용자 질문: {user_question}                                              \n",
        "\"\"\")\n",
        "\n",
        "# 맥락이 풍부한 프롬프트의 예\n",
        "good_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "사용자 질문: {user_question}\n",
        "\n",
        "배경: 65세 이상 노인을 대상으로 하는 스마트폰 교육 프로그램을 진행하고 있습니다.\n",
        "목적: 처음 스마트폰을 사용하는 노인들이 기본 기능을 쉽게 익힐 수 있도록 돕고자 합니다.\n",
        "대상: 디지털 기기 사용 경험이 거의 없는 노인입니다.\n",
        "\n",
        "위 맥락을 고려하여 응답해주세요.\n",
        "\n",
        "응답 형식:\n",
        "- 쉬운 용어 사용\n",
        "- 단계별 설명\n",
        "- 구체적인 예시 포함\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# LCEL 체인\n",
        "good_chain = good_prompt | llm \n",
        "bad_chain = bad_prompt | llm\n",
        "\n",
        "# 테스트\n",
        "question = \"아이폰에 카카오톡 설치하는 방법을 알려주세요.\"\n",
        "good_result = good_chain.invoke({\"user_question\": question})\n",
        "bad_result = bad_chain.invoke({\"user_question\": question})\n",
        "\n",
        "print(\"맥락이 부족한 프롬프트의 결과\")\n",
        "pprint(bad_result.content)\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"맥락이 풍부한 프롬프트의 결과\")\n",
        "pprint(good_result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. **구조화(Structure)**\n",
        "\n",
        "- 프롬프트 입력의 구조화: PromptTemplate, ChatPromptTemplate 사용\n",
        "- LLM 출력의 구조화: OutputParser, Schema 사용\n",
        "\n",
        "- 기대효과:\n",
        "    - 일관된 형식의 입출력 보장\n",
        "    - 데이터 처리 및 후속 작업의 용이성\n",
        "    - 오류 처리의 체계화\n",
        "    - 재사용성 향상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) 프롬프트 템플릿 (Prompt Template)\n",
        "\n",
        "- **프롬프트 템플릿**은 LLM과의 상호작용을 구조화하는 핵심 도구\n",
        "\n",
        "- 템플릿은 다양한 입력값으로 **재사용**이 가능하며 **유연한 변수 처리**를 지원\n",
        "\n",
        "- **검증 기능**과 **부분 포맷팅**을 통해 프롬프트 작성의 안정성을 보장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) 기본 템플릿`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "다음 주제에 대해 설명해주세요: 인공지능\n",
            "포함해야 할 내용: 정의, 역사, 응용분야\n",
            "글자수: 500자\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 정의\n",
        "template = \"\"\"\n",
        "다음 주제에 대해 설명해주세요: {topic}\n",
        "포함해야 할 내용: {content}\n",
        "글자수: {length}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"topic\", \"content\", \"length\"]\n",
        ")\n",
        "\n",
        "# 템플릿 사용\n",
        "formatted_prompt = prompt.format(\n",
        "    topic=\"인공지능\",\n",
        "    content=\"정의, 역사, 응용분야\",\n",
        "    length=\"500자\"\n",
        ")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) from_template 메소드`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "다음 주제에 대해 설명해주세요: 인공지능\n",
            "포함해야 할 내용: 정의, 역사, 응용분야\n",
            "글자수: 500자\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 문자열 정의\n",
        "template = \"\"\"\n",
        "다음 주제에 대해 설명해주세요: {topic}\n",
        "포함해야 할 내용: {content}\n",
        "글자수: {length}\n",
        "\"\"\"\n",
        "\n",
        "# 템플릿 생성 (템플릿 문자열 지정)\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 템플릿 사용 (입력 변수 지정)\n",
        "formatted_prompt = prompt.format(\n",
        "    topic=\"인공지능\",\n",
        "    content=\"정의, 역사, 응용분야\",\n",
        "    length=\"500자\"\n",
        ")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(3) 템플릿 검증 및 부분 포맷팅`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "부분적으로 변수 채워진 템플릿: input_variables=['feature'] input_types={} partial_variables={'product': '스마트폰'} template='{product}의 다음 특징을 분석해주세요: {feature}' validate_template=True\n",
            "----------------------------------------------------------------------------------------------------\n",
            "나머지 변수 채워진 템플릿: 스마트폰의 다음 특징을 분석해주세요: 카메라\n",
            "----------------------------------------------------------------------------------------------------\n",
            "다른 변수 채워진 템플릿: 스마트폰의 다음 특징을 분석해주세요: 배터리 수명\n",
            "----------------------------------------------------------------------------------------------------\n",
            "모든 변수 채워진 템플릿: 노트북의 다음 특징을 분석해주세요: 배터리 수명\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 템플릿 생성 \n",
        "template = PromptTemplate(\n",
        "    template=\"{product}의 다음 특징을 분석해주세요: {feature}\",  # 템플릿 문자열\n",
        "    input_variables=[\"product\", \"feature\"],  # 입력 변수 목록\n",
        "    validate_template=True  # 템플릿 유효성 검증\n",
        ")\n",
        "\n",
        "# 부분적으로 변수 채우기\n",
        "partial_prompt = template.partial(product=\"스마트폰\")\n",
        "\n",
        "print(f\"부분적으로 변수 채워진 템플릿: {partial_prompt}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# 나중에 나머지 변수 채우기\n",
        "final_prompt1 = partial_prompt.format(feature=\"카메라\")\n",
        "\n",
        "print(f\"나머지 변수 채워진 템플릿: {final_prompt1}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# 다른 특징을 분석하도록 변수 변경\n",
        "final_prompt2 = partial_prompt.format(feature=\"배터리 수명\")\n",
        "\n",
        "print(f\"다른 변수 채워진 템플릿: {final_prompt2}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# 모든 변수를 한 번에 채우기\n",
        "final_prompt3 = template.format(product=\"노트북\", feature=\"배터리 수명\")\n",
        "\n",
        "print(f\"모든 변수 채워진 템플릿: {final_prompt3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "템플릿 유효성 검증 실패: 'feature'\n"
          ]
        }
      ],
      "source": [
        "# 템플릿 유효성 검증 실패\n",
        "try:\n",
        "    invalid_prompt = template.format(product=\"스마트폰\")\n",
        "except KeyError as e:\n",
        "    print(f\"템플릿 유효성 검증 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) 챗 프롬프트 템플릿 (Chat Prompt Template)\n",
        "\n",
        "- **챗 프롬프트 템플릿**은 대화형 AI와의 상호작용을 위한 특화된 템플릿\n",
        "\n",
        "- 시스템/사용자/어시스턴트 등 **다양한 역할**의 메시지를 구조화\n",
        "\n",
        "- 대화의 **맥락과 흐름**을 유지하면서 일관된 상호작용 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) 메시지 템플릿 사용`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System: 당신은 인공지능 전문가입니다. 친절한 스타일로 답변해주세요.\n",
            "Human: 인공지능의 정의를 설명해주세요.\n"
          ]
        }
      ],
      "source": [
        "### 2. 복잡한 템플릿 구성:\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# 개별 메시지 템플릿 생성\n",
        "system_message = SystemMessagePromptTemplate.from_template(\n",
        "    \"당신은 {role} 전문가입니다. {style} 스타일로 답변해주세요.\"\n",
        ")\n",
        "\n",
        "human_message = HumanMessagePromptTemplate.from_template(\n",
        "    \"{question}\"\n",
        ")\n",
        "\n",
        "# from_messages 메소드 사용 (여러 개의 메시지들을 원소로 갖는 리스트로 구성)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    system_message,\n",
        "    human_message\n",
        "])\n",
        "\n",
        "# 템플릿 사용\n",
        "formatted_prompt = chat_prompt.format(\n",
        "    role=\"인공지능\",\n",
        "    style=\"친절한\",\n",
        "    question=\"인공지능의 정의를 설명해주세요.\"\n",
        ")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) 문자열 템플릿 사용`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: \n",
            "당신은 인공지능 전문가입니다. 친절한 스타일로 답변해주세요.\n",
            "\n",
            "인공지능의 정의를 설명해주세요.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# 시스템 메시지와 사용자 메시지를 포함한 템플릿 정의\n",
        "template = \"\"\"\n",
        "당신은 {role} 전문가입니다. {style} 스타일로 답변해주세요.\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "# from_template 메소드 사용 (단일 템플릿 문자열 직접 사용)\n",
        "chat_prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 템플릿 사용\n",
        "formatted_prompt = chat_prompt.format(\n",
        "    role=\"인공지능\",\n",
        "    style=\"친절한\",\n",
        "    question=\"인공지능의 정의를 설명해주세요.\"\n",
        ")\n",
        "\n",
        "# ChatPromptTemplate을 직접 생성 - 이때는 HumanMessage로 처리됨 (SystemMessage는 별도로 추가해야 함)\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2)  OutputParser 활용\n",
        "\n",
        "- **OutputParser**는 LLM의 출력을 다양한 데이터 형식으로 변환하는 도구\n",
        "\n",
        "- **문자열**, **JSON**, **XML** 등 여러 형식의 파싱을 지원\n",
        "\n",
        "- 파싱된 출력은 **다른 시스템**이나 **프로세스**와 연동하는데 유용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) JSONOutputParser`\n",
        "- LLM의 출력을 **구조화된 JSON**으로 변환\n",
        "- 파서는 출력의 **데이터 유효성**을 검증하고 일관된 형식을 보장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('The output should be formatted as a JSON instance that conforms to the JSON '\n",
            " 'schema below.\\n'\n",
            " '\\n'\n",
            " 'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", '\n",
            " '\"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": '\n",
            " '\"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
            " 'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the '\n",
            " 'schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not '\n",
            " 'well-formatted.\\n'\n",
            " '\\n'\n",
            " 'Here is the output schema:\\n'\n",
            " '```\\n'\n",
            " '{\"properties\": {\"name\": {\"description\": \"관광명소 이름\", \"title\": \"Name\", \"type\": '\n",
            " '\"string\"}, \"location\": {\"description\": \"위치 (구/동 정보)\", \"title\": \"Location\", '\n",
            " '\"type\": \"string\"}, \"category\": {\"description\": \"카테고리 (궁궐/박물관/쇼핑 등)\", '\n",
            " '\"title\": \"Category\", \"type\": \"string\"}, \"highlights\": {\"description\": \"주요 관람 '\n",
            " '포인트\", \"items\": {\"type\": \"string\"}, \"title\": \"Highlights\", \"type\": \"array\"}}, '\n",
            " '\"required\": [\"name\", \"location\", \"category\", \"highlights\"]}\\n'\n",
            " '```')\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# 관광지 정보를 위한 Pydantic 모델 정의 (이름, 위치, 카테고리, 주요 관람 포인트)\n",
        "class TouristSpot(BaseModel):\n",
        "    name: str = Field(description=\"관광명소 이름\")\n",
        "    location: str = Field(description=\"위치 (구/동 정보)\")\n",
        "    category: str = Field(description=\"카테고리 (궁궐/박물관/쇼핑 등)\")\n",
        "    highlights: List[str] = Field(description=\"주요 관람 포인트\")\n",
        "\n",
        "# JsonOutputParser 파서 설정 (Pydantic 모델 지정)\n",
        "parser = JsonOutputParser(pydantic_object=TouristSpot)\n",
        "\n",
        "# parser의 get_format_instructions 메소드 사용 (포맷 지시사항 출력)\n",
        "pprint(parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('서울의 다음 관광명소에 대한 상세 정보를 제공해주세요.\\n'\n",
            " 'The output should be formatted as a JSON instance that conforms to the JSON '\n",
            " 'schema below.\\n'\n",
            " '\\n'\n",
            " 'As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", '\n",
            " '\"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": '\n",
            " '\"string\"}}}, \"required\": [\"foo\"]}\\n'\n",
            " 'the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the '\n",
            " 'schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not '\n",
            " 'well-formatted.\\n'\n",
            " '\\n'\n",
            " 'Here is the output schema:\\n'\n",
            " '```\\n'\n",
            " '{\"properties\": {\"name\": {\"description\": \"관광명소 이름\", \"title\": \"Name\", \"type\": '\n",
            " '\"string\"}, \"location\": {\"description\": \"위치 (구/동 정보)\", \"title\": \"Location\", '\n",
            " '\"type\": \"string\"}, \"category\": {\"description\": \"카테고리 (궁궐/박물관/쇼핑 등)\", '\n",
            " '\"title\": \"Category\", \"type\": \"string\"}, \"highlights\": {\"description\": \"주요 관람 '\n",
            " '포인트\", \"items\": {\"type\": \"string\"}, \"title\": \"Highlights\", \"type\": \"array\"}}, '\n",
            " '\"required\": [\"name\", \"location\", \"category\", \"highlights\"]}\\n'\n",
            " '```\\n'\n",
            " '\\n'\n",
            " '관광지: 경복궁\\n')\n"
          ]
        }
      ],
      "source": [
        "# 프롬프트 템플릿 정의 (parser의 get_format_instructions 메소드 사용)\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"서울의 다음 관광명소에 대한 상세 정보를 제공해주세요.\n",
        "{format_instructions}\n",
        "\n",
        "관광지: {spot_name}\n",
        "\"\"\",\n",
        "    input_variables=[\"spot_name\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# 완성된 프롬프트 템플릿 출력 (포맷 지시사항 포함)\n",
        "pprint(prompt.format(spot_name=\"경복궁\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'category': '궁궐',\n",
            " 'highlights': ['조선 시대의 대표적인 궁궐로서 한국 전통 건축의 아름다움을 감상할 수 있음',\n",
            "                '근정전, 경회루 등 주요 건축물 관람',\n",
            "                '한복 체험 및 전통 문화 행사 참여 가능',\n",
            "                '광화문과 청와대 인근 위치로 접근성 우수'],\n",
            " 'location': '종로구 세종로',\n",
            " 'name': '경복궁'}\n"
          ]
        }
      ],
      "source": [
        "# 체인 구성\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# 실행 예시\n",
        "result = chain.invoke({\n",
        "    \"spot_name\": \"경복궁\"\n",
        "})\n",
        "\n",
        "# 결과 출력\n",
        "pprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) XMLOutputParser`\n",
        "- LLM의 출력을 **구조화된 XML** 형식으로 변환\n",
        "- XML 구조는 **계층적 데이터**를 표현하는데 효과적\n",
        "- 패키지 설치: defusedxml "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('The output should be formatted as a XML file.\\n'\n",
            " '1. Output should conform to the tags below.\\n'\n",
            " '2. If tags are not given, make them on your own.\\n'\n",
            " '3. Remember to always open and close all the tags.\\n'\n",
            " '\\n'\n",
            " 'As an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n'\n",
            " '1. String \"<foo>\\n'\n",
            " '   <bar>\\n'\n",
            " '      <baz></baz>\\n'\n",
            " '   </bar>\\n'\n",
            " '</foo>\" is a well-formatted instance of the schema.\\n'\n",
            " '2. String \"<foo>\\n'\n",
            " '   <bar>\\n'\n",
            " '   </foo>\" is a badly-formatted instance.\\n'\n",
            " '3. String \"<foo>\\n'\n",
            " '   <tag>\\n'\n",
            " '   </tag>\\n'\n",
            " '</foo>\" is a badly-formatted instance.\\n'\n",
            " '\\n'\n",
            " 'Here are the output tags:\\n'\n",
            " '```\\n'\n",
            " \"['tourist_spot', 'name', 'location', 'category', 'highlights', 'point']\\n\"\n",
            " '```')\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import XMLOutputParser\n",
        "\n",
        "# XML 파서 설정 - 원하는 태그 구조 정의\n",
        "parser = XMLOutputParser(tags=[\"tourist_spot\", \"name\", \"location\", \"category\", \"highlights\", \"point\"])\n",
        "\n",
        "# parser의 get_format_instructions 메소드 사용 (포맷 지시사항 출력)\n",
        "pprint(parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('서울의 다음 관광명소에 대한 상세 정보를 XML 형식으로 제공해주세요.\\n'\n",
            " 'The output should be formatted as a XML file.\\n'\n",
            " '1. Output should conform to the tags below.\\n'\n",
            " '2. If tags are not given, make them on your own.\\n'\n",
            " '3. Remember to always open and close all the tags.\\n'\n",
            " '\\n'\n",
            " 'As an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n'\n",
            " '1. String \"<foo>\\n'\n",
            " '   <bar>\\n'\n",
            " '      <baz></baz>\\n'\n",
            " '   </bar>\\n'\n",
            " '</foo>\" is a well-formatted instance of the schema.\\n'\n",
            " '2. String \"<foo>\\n'\n",
            " '   <bar>\\n'\n",
            " '   </foo>\" is a badly-formatted instance.\\n'\n",
            " '3. String \"<foo>\\n'\n",
            " '   <tag>\\n'\n",
            " '   </tag>\\n'\n",
            " '</foo>\" is a badly-formatted instance.\\n'\n",
            " '\\n'\n",
            " 'Here are the output tags:\\n'\n",
            " '```\\n'\n",
            " \"['tourist_spot', 'name', 'location', 'category', 'highlights', 'point']\\n\"\n",
            " '```\\n'\n",
            " '\\n'\n",
            " '관광지: 경복궁')\n"
          ]
        }
      ],
      "source": [
        "# 프롬프트 템플릿 정의\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"서울의 다음 관광명소에 대한 상세 정보를 XML 형식으로 제공해주세요.\n",
        "{format_instructions}\n",
        "\n",
        "관광지: {spot_name}\"\"\",\n",
        "    input_variables=[\"spot_name\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}  \n",
        ")\n",
        "\n",
        "# 완성된 프롬프트 템플릿 출력 (포맷 지시사항 포함)\n",
        "pprint(prompt.format(spot_name=\"경복궁\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tourist_spot': [{'name': '경복궁'},\n",
            "                  {'location': '서울특별시 종로구 사직로 161'},\n",
            "                  {'category': '역사/문화유적'},\n",
            "                  {'highlights': [{'point': '조선 왕조의 정궁으로서 한국 전통 건축의 아름다움을 감상할 '\n",
            "                                            '수 있음'},\n",
            "                                  {'point': '근정전, 경회루 등 주요 건축물과 아름다운 정원'},\n",
            "                                  {'point': '한복 체험 및 수문장 교대식 관람 가능'},\n",
            "                                  {'point': '국립고궁박물관과 국립민속박물관이 인접해 있어 역사 교육에 '\n",
            "                                            '적합'}]}]}\n"
          ]
        }
      ],
      "source": [
        "# 체인 구성\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# 실행 예시\n",
        "result = chain.invoke({\n",
        "    \"spot_name\": \"경복궁\"\n",
        "})\n",
        "\n",
        "# 결과는 Python 딕셔너리 형태로 파싱되어 반환됨 \n",
        "pprint(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': '경복궁'},\n",
              " {'location': '서울특별시 종로구 사직로 161'},\n",
              " {'category': '역사/문화유적'},\n",
              " {'highlights': [{'point': '조선 왕조의 정궁으로서 한국 전통 건축의 아름다움을 감상할 수 있음'},\n",
              "   {'point': '근정전, 경회루 등 주요 건축물과 아름다운 정원'},\n",
              "   {'point': '한복 체험 및 수문장 교대식 관람 가능'},\n",
              "   {'point': '국립고궁박물관과 국립민속박물관이 인접해 있어 역사 교육에 적합'}]}]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# XML 형식의 결과를 다시 파싱하여 출력 (가장 상위 태그를 제외한 내용만 출력)\n",
        "result['tourist_spot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(3) 사용자 정의(Custom) OutputParser`\n",
        "- **사용자 정의 파서**는 **RunnableLambda**나 **RunnableGenerator**를 활용하여 구현\n",
        "- 특정 비즈니스 요구사항에 맞는 **맞춤형 출력 형식**을 정의할 수 있음 \n",
        "- 복잡한 **데이터 변환**과 **후처리 로직**을 유연하게 구현할 수 있음 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'description': '조선 시대의 대표적인 궁궐로, 서울에 위치해 있습니다. 아름다운 건축과 역사적 의미가 깊어 많은 관광객이 '\n",
            "                '방문합니다.',\n",
            " 'name': '경복궁  '}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from typing import Dict\n",
        "\n",
        "# 사용자 정의 파서\n",
        "def parse_tourist_spot(ai_message: AIMessage) -> Dict:\n",
        "    \"\"\"관광지 정보를 딕셔너리로 파싱\"\"\"\n",
        "    lines = ai_message.content.split('\\n')\n",
        "    return {\n",
        "        \"name\": lines[0] if lines else \"\",\n",
        "        \"description\": ' '.join(lines[1:]) if len(lines) > 1 else \"\"\n",
        "    }\n",
        "\n",
        "# 프롬프트 템플릿\n",
        "prompt = PromptTemplate(\n",
        "    template=\"다음 관광지에 대해 첫 줄에 이름, 다음 줄부터 설명을 100자 내외로 작성해주세요:\\n{spot_name}\",\n",
        "    input_variables=[\"spot_name\"]\n",
        ")\n",
        "\n",
        "# 체인 구성 (invoke 방식)\n",
        "invoke_chain = prompt | llm | parse_tourist_spot\n",
        "\n",
        "# 체인 실행\n",
        "result = invoke_chain.invoke({\n",
        "    \"spot_name\": \"경복궁\"\n",
        "})\n",
        "\n",
        "pprint(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏛 \n",
            "🏛 광\n",
            "🏛 화\n",
            "🏛 문\n",
            "🏛   \n",
            "\n",
            "🏛 서울\n",
            "🏛 의\n",
            "🏛  중심\n",
            "🏛 에\n",
            "🏛  위치\n",
            "🏛 한\n",
            "🏛  조\n",
            "🏛 선\n",
            "🏛  시대\n",
            "🏛 의\n",
            "🏛  정\n",
            "🏛 문\n",
            "🏛 으로\n",
            "🏛 ,\n",
            "🏛  역사\n",
            "🏛 적\n",
            "🏛  상\n",
            "🏛 징\n",
            "🏛 성과\n",
            "🏛  문화\n",
            "🏛 적\n",
            "🏛  의미\n",
            "🏛 가\n",
            "🏛  깊\n",
            "🏛 은\n",
            "🏛  명\n",
            "🏛 소\n",
            "🏛 입니다\n",
            "🏛 .\n",
            "🏛 \n"
          ]
        }
      ],
      "source": [
        "## 위 구현을 stream 방식으로 변경\n",
        "\n",
        "from langchain_core.runnables import RunnableGenerator\n",
        "from langchain_core.messages import AIMessageChunk\n",
        "from typing import Iterable\n",
        "import time\n",
        "\n",
        "# 사용자 정의 파서 (stream 방식) \n",
        "def streaming_parse_tourist_spot(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
        "    \"\"\"실시간으로 관광지 정보 파싱\"\"\"\n",
        "    for chunk in chunks:\n",
        "        yield f\"🏛 {chunk.content}\"   # 🏛 이모지 추가 \n",
        "\n",
        "# stream 방식 체인 구성 \n",
        "streaming_chain = prompt | llm | RunnableGenerator(streaming_parse_tourist_spot)\n",
        "\n",
        "# 체인 실행 \n",
        "for chunk in streaming_chain.stream({\"spot_name\": \"광화문\"}):\n",
        "    print(chunk)\n",
        "    time.sleep(0.1)   # 시간 지연 추가 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**[참고] 이모지(emoji) 입력 방법**\n",
        "\n",
        "1. Windows에서:\n",
        "    - `Windows 키 + .` (윈도우 키와 마침표를 동시에 누름)\n",
        "    - 또는 `Windows 키 + ;` (윈도우 키와 세미콜론을 동시에 누름)\n",
        "\n",
        "2. Mac에서:\n",
        "    - `fn(지구본) 키 + E` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(3) 구조화된 출력 프롬프트 (Structured Output Prompts)`\n",
        "   - 일관된 형식의 응답\n",
        "   - 데이터 처리 용이"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'keywords': ['양자 컴퓨팅', '큐비트', '중첩 상태'],\n",
            " 'sentiment': '중립',\n",
            " 'summary': '양자 컴퓨팅은 양자역학 원리를 이용해 큐비트를 활용하여 기존 컴퓨터보다 더 빠르고 복잡한 계산을 수행하는 새로운 계산 '\n",
            "            '방식이다.'}\n"
          ]
        }
      ],
      "source": [
        "# typing 사용\n",
        "from typing import TypedDict, Annotated \n",
        "\n",
        "class AnalysisResult(TypedDict):\n",
        "    \"\"\"분석 결과 스키마\"\"\"\n",
        "    summary: Annotated[str, ..., \"핵심 요약\"]\n",
        "    keywords: Annotated[list[str], ..., \"주요 키워드\"]\n",
        "    sentiment: Annotated[str, ..., \"긍정/부정/중립\"]\n",
        "\n",
        "structured_llm = llm.with_structured_output(AnalysisResult)\n",
        "\n",
        "step_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 텍스트에 대해서 작업을 순서대로 수행하세요:\n",
        "\n",
        "    [텍스트]\n",
        "    {text}\n",
        "\n",
        "    [작업 순서]\n",
        "    1. 텍스트를 1문장으로 요약\n",
        "    2. 핵심 키워드 3개 추출\n",
        "    3. 감정 분석 수행(긍정/부정/중립)\n",
        "\n",
        "    [작업 결과]\n",
        "    \"\"\",\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "# LCEL\n",
        "chain = step_prompt | structured_llm\n",
        "\n",
        "# 질문\n",
        "text = \"\"\"\n",
        "양자 컴퓨팅은 양자역학의 원리를 바탕으로 데이터를 처리하는 새로운 형태의 계산 방식이다.\n",
        "기존의 고전적 컴퓨터는 0과 1로 이루어진 이진법(bit)을 사용하여 데이터를 처리하지만,\n",
        "양자 컴퓨터는 양자 비트(큐비트, qubit)를 사용하여 훨씬 더 복잡하고 빠른 계산을 수행할 수 있다.\n",
        "\n",
        "큐비트는 동시에 0과 1의 상태를 가질 수 있는 양자 중첩(superposition) 상태를 활용하며,\n",
        "이를 통해 병렬 계산과 같은 고급 기능이 가능하다.\n",
        "\"\"\"\n",
        "\n",
        "output = chain.invoke({\"text\": text})\n",
        "pprint(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "summary='양자 컴퓨팅은 양자역학 원리를 이용해 큐비트를 활용하여 기존 컴퓨터보다 더 빠르고 복잡한 계산을 수행하는 새로운 계산 방식이다.' keywords=['양자 컴퓨팅', '큐비트', '양자 중첩'] sentiment='중립'\n",
            "<class '__main__.AnalysisResult'>\n",
            "----------------------------------------------------------------------------------------------------\n",
            "양자 컴퓨팅은 양자역학 원리를 이용해 큐비트를 활용하여 기존 컴퓨터보다 더 빠르고 복잡한 계산을 수행하는 새로운 계산 방식이다.\n",
            "['양자 컴퓨팅', '큐비트', '양자 중첩']\n",
            "중립\n"
          ]
        }
      ],
      "source": [
        "# pydantic 사용\n",
        "from typing import List, Literal\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class AnalysisResult(BaseModel):\n",
        "    \"\"\"텍스트 분석 결과를 담는 스키마\"\"\"\n",
        "    \n",
        "    summary: str = Field(\n",
        "        ...,  # ... 은 required 필드를 의미 (필수 입력, None 허용 안함)\n",
        "        description=\"텍스트의 핵심 내용 요약\"\n",
        "    )\n",
        "    \n",
        "    keywords: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"텍스트에서 추출한 주요 키워드\"\n",
        "    )\n",
        "    \n",
        "    sentiment: Literal[\"긍정\", \"부정\", \"중립\"] = Field(\n",
        "        ...,\n",
        "        description=\"텍스트의 전반적인 감정 분석 결과\"\n",
        "    )\n",
        "\n",
        "structured_llm = llm.with_structured_output(AnalysisResult)\n",
        "\n",
        "# LCEL\n",
        "chain = step_prompt | structured_llm\n",
        "\n",
        "# 질문\n",
        "output = chain.invoke({\"text\": text})\n",
        "print(output)\n",
        "print(type(output))\n",
        "print(\"-\"*100)\n",
        "print(output.summary)\n",
        "print(output.keywords)\n",
        "print(output.sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [실습 프로젝트]\n",
        "\n",
        "### 맞춤형 학습 도우미 챗봇 만들기\n",
        "\n",
        "- 특정 주제에 대한 학습을 돕는 챗봇을 만들어봅니다. 앞서 배운 프롬프트 유형들을 조합하여 활용합니다.\n",
        "\n",
        "- (1) 퀴즈 문제 예시를 보고, (2) 개념 설명 체인을 완성합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(1) 퀴즈 문제 출제 (예시)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"퀴즈 문제: 딥러닝에서 '과적합(overfitting)' 문제를 완화하기 위한 대표적인 기법이 아닌 것은 무엇인가?\"\n",
            "(\"보기: ['드롭아웃(Dropout)', '조기 종료(Early Stopping)', '데이터 증강(Data Augmentation)', \"\n",
            " \"'배치 정규화(Batch Normalization)', '배치 정규화(Batch Normalization)']\")\n",
            "'정답: 4'\n",
            "('정답 설명: 과적합은 모델이 학습 데이터에 너무 치중하여 일반화 성능이 떨어지는 현상입니다. 이를 완화하기 위해 드롭아웃, 조기 종료, '\n",
            " '데이터 증강 등이 사용됩니다. 배치 정규화는 학습을 안정화하고 속도를 높이기 위한 기법으로, 직접적으로 과적합을 완화하는 기법은 '\n",
            " '아닙니다.')\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 퀴즈 문제 스키마\n",
        "class QuizQuestion(BaseModel):\n",
        "    \"\"\"퀴즈 문제 스키마\"\"\"\n",
        "    question: str = Field(..., description=\"퀴즈 문제\")\n",
        "    options: List[str] = Field(..., description=\"보기 (4개)\")\n",
        "    correct_answer: int = Field(..., description=\"정답 번호 (1-4)\")\n",
        "    explanation: str = Field(..., description=\"정답 설명\")\n",
        "\n",
        "\n",
        "# 퀴즈 생성을 위한 구조화된 출력 프롬프트\n",
        "quiz_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 주제에 대한 퀴즈 문제를 만들어주세요:\n",
        "    \n",
        "주제: {topic}\n",
        "난이도(상/중/하): {difficulty}\n",
        "\n",
        "다음 조건을 만족하는 퀴즈를 생성해주세요:\n",
        "1. 문제는 명확하고 이해하기 쉽게\n",
        "2. 4개의 보기 제공\n",
        "3. 정답과 오답은 비슷한 수준으로\n",
        "4. 상세한 정답 설명 포함\"\"\",\n",
        "    input_variables=[\"topic\", \"difficulty\"]\n",
        ")\n",
        "\n",
        "# LLM 정의\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
        "\n",
        "# 구조화된 출력 파서 설정\n",
        "structured_llm = llm.with_structured_output(QuizQuestion)\n",
        "\n",
        "# LCEL 체인 구성\n",
        "chain = quiz_prompt | structured_llm\n",
        "\n",
        "# 질문 실행\n",
        "output = chain.invoke({\"topic\": \"인공지능\", \"difficulty\": \"상\"})\n",
        "\n",
        "# 결과 출력\n",
        "pprint(f\"퀴즈 문제: {output.question}\")\n",
        "pprint(f\"보기: {output.options}\")\n",
        "pprint(f\"정답: {output.correct_answer}\")\n",
        "pprint(f\"정답 설명: {output.explanation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2) 개념 설명 체인 (문제)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'주제: Splunk'\n",
            "'설명: 데이터 검색, 모니터링, 분석 플랫폼'\n",
            "\"예시: ['서버 로그 실시간 분석', '보안 이벤트 탐지']\"\n",
            "\"관련 개념: ['로그 관리', '데이터 시각화', '보안 정보 이벤트 관리(SIEM)']\"\n"
          ]
        }
      ],
      "source": [
        "# 개념 설명을 위한 스키마\n",
        "class ConceptExplanation(BaseModel):\n",
        "    \"\"\"개념 설명 스키마\"\"\"\n",
        "    topic: str = Field(..., description=\"개념\")\n",
        "    explanation: str = Field(..., description=\"개념 설명\")\n",
        "    examples: List[str] = Field(..., description=\"개념 예시\")\n",
        "    related_concepts: List[str] = Field(..., description=\"관련 개념\")\n",
        "\n",
        "# 개념 설명을 위한 지시형 프롬프트\n",
        "concept_prompt = PromptTemplate(\n",
        "    template=\"\"\"다음 주제에 대한 개념을 설명해주세요:\n",
        "    \n",
        "주제: {topic}\n",
        "\n",
        "다음 조건을 만족하는 퀴즈를 생성해주세요:\n",
        "1. 개념은 명확하고 이해하기 쉽게\n",
        "2. 2개의 예시를 제공\n",
        "3. 최대 50자 이내로 설명\n",
        "4. 관련 개념 3개 포함\n",
        "\"\"\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "# 구조화된 출력 파서 설정\n",
        "structured_llm = llm.with_structured_output(ConceptExplanation)\n",
        "\n",
        "# LCEL 체인 구성\n",
        "chain = concept_prompt | structured_llm\n",
        "\n",
        "# 질문 실행\n",
        "output = chain.invoke({\"topic\": \"Splunk\"})\n",
        "\n",
        "# 결과 출력\n",
        "pprint(f\"주제: {output.topic}\")\n",
        "pprint(f\"설명: {output.explanation}\")\n",
        "pprint(f\"예시: {output.examples}\")\n",
        "pprint(f\"관련 개념: {output.related_concepts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "faq_chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

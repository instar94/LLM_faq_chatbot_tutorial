{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV-Z1B-Pa4L1"
   },
   "source": [
    "# ğŸ¤– LLM ì›ë¦¬ + OpenAI Chat Completion API í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "## 1. LLM ê¸°ë³¸ ê°œë…\n",
    "\n",
    "### ğŸ§  LLM(Large Language Model)ì˜ ìƒì„± ì›ë¦¬\n",
    "\n",
    "**LLMì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**\n",
    "- **íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°**: ëŒ€í™”í˜• AIì˜ í•µì‹¬ ì•„í‚¤í…ì²˜\n",
    "- **í† í° ì˜ˆì¸¡**: ë‹¤ìŒì— ì˜¬ ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
    "- **í•™ìŠµ ë°©ì‹**: ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨\n",
    "\n",
    "**í•µì‹¬ í”„ë¡œì„¸ìŠ¤**\n",
    "1. **í† í°í™”**: í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(í† í°)ë¡œ ë¶„í• \n",
    "2. **í™•ë¥  ê³„ì‚°**: ê° í† í°ì´ ë‹¤ìŒì— ì˜¬ í™•ë¥  ê³„ì‚°\n",
    "3. **í† í° ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¼ í† í° ì„ íƒ\n",
    "4. **ë°˜ë³µ**: ì¢…ë£Œ ì¡°ê±´ê¹Œì§€ ê³¼ì • ë°˜ë³µ\n",
    "\n",
    "\n",
    "**íŠ¸ëœìŠ¤í¬ë¨¸**:\n",
    "- **ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë™ì‹œì— ì²˜ë¦¬\n",
    "- **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì…ë ¥ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ì— ì§‘ì¤‘\n",
    "\n",
    "\n",
    "<div style=\"text-align: left; font-size: 12px;\">\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Transformer%2C_full_architecture.png/440px-Transformer%2C_full_architecture.png\"\n",
    "        alt=\"Illustrations for the Transformer and attention mechanism showing the full Transformer architecture\"\n",
    "        width=\"600\"\n",
    "        style=\"border: 0;\">\n",
    "</div>\n",
    "\n",
    "**Image Title:** Transformer Architecture Illustration  \n",
    "**Source:** [GitHub - DL Visuals](https://github.com/dvgodoy/dl-visuals/?tab=readme-ov-file)  \n",
    "**License:** [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)  \n",
    "**Author(s):** dvgodoy  \n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2. OpenAI API í•µì‹¬ ê°œë…\n",
    "\n",
    "### ğŸ”§ ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "**1. ë©”ì‹œì§€ í˜•ì‹**\n",
    "\n",
    "  ```python\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "      {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"sort() ë©”ì„œë“œë‚˜ sorted() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"}\n",
    "  ]\n",
    "  ```\n",
    "\n",
    "**2. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ (2025ë…„ ê¸°ì¤€)**\n",
    "\n",
    "  - **gpt-4.1**: ìµœê³  ì„±ëŠ¥, ë³µì¡í•œ ì‘ì—…ìš©\n",
    "  - **gpt-4.1-mini**: ë¹ ë¥¸ ì†ë„, ë¹„ìš© íš¨ìœ¨ì \n",
    "  - **gpt-4.1-nano**: ì´ˆê³ ì†, ìµœì € ë¹„ìš©\n",
    "  - **o3, o4-mini**: ë³µì¡í•œ ì¶”ë¡  ì‘ì—…ìš©\n",
    "  - **gpt-4o**: ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)\n",
    "\n",
    "**3. API ì‘ë‹µ êµ¬ì¡°**\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"id\": \"chatcmpl-...\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"model\": \"gpt-4.1-mini\",\n",
    "    \"choices\": [\n",
    "      {\n",
    "        \"message\": {\n",
    "          \"role\": \"assistant\", \n",
    "          \"content\": \"ìƒì„±ëœ í…ìŠ¤íŠ¸\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"prompt_tokens\": 10,\n",
    "      \"completion_tokens\": 50,\n",
    "      \"total_tokens\": 60\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 3. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "\n",
    "### ğŸš€ uv í”„ë¡œì íŠ¸ ì„¤ì •\n",
    "- **í”„ë¡œì íŠ¸ ìƒì„±**: `uv init [í”„ë¡œì íŠ¸ëª…]`\n",
    "- **ê°€ìƒí™˜ê²½ ìƒì„±**: `uv venv --python=3.12`\n",
    "- **ê°€ìƒí™˜ê²½ í™œì„±í™”**: `.venv/bin/activate` (Unix) ë˜ëŠ” `.venv\\Scripts\\activate` (Windows)\n",
    "\n",
    "\n",
    "### ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "```bash\n",
    "# uv ì‚¬ìš© (ê¶Œì¥)\n",
    "uv add langchain langchain_openai python-dotenv ipykernel\n",
    "\n",
    "# pip ì‚¬ìš©\n",
    "pip install langchain langchain_openai python-dotenv ipykernel\n",
    "```\n",
    "\n",
    "### ğŸ” API í‚¤ ì„¤ì •\n",
    "```python\n",
    "# .env íŒŒì¼ ìƒì„±\n",
    "OPENAI_API_KEY=your_api_key_here\n",
    "\n",
    "# Pythonì—ì„œ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 4. ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ìŠ¤íŠ¸ ë‹µë³€ì„ ìƒì„±\n",
    "\n",
    "* OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "  - `from openai import OpenAI`ë¡œ OpenAI íŒ¨í‚¤ì§€ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤\n",
    "  - `client = OpenAI()`ë¡œ API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "  - API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë‚˜ ì§ì ‘ ì„¤ì •ì„ í†µí•´ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "  - ë³´ì•ˆì„ ìœ„í•´ API í‚¤ëŠ” `.env` íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤\n",
    "\n",
    "* Chat Completion ìš”ì²­ êµ¬ì¡°\n",
    "  - `client.chat.completions.create()`ë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤\n",
    "  - `model`: ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì • (ì˜ˆ: \"gpt-4-mini\")\n",
    "  - `messages`: ëŒ€í™” ë§¥ë½ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì „ë‹¬\n",
    "    - `role`: \"developer\", \"user\" ë“±ì˜ ì—­í•  ì§€ì •\n",
    "    - `content`: ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš©\n",
    "  - `temperature`: ìƒì„± í…ìŠ¤íŠ¸ì˜ ë¬´ì‘ìœ„ì„± ì¡°ì ˆ (0~1)\n",
    "  - `max_tokens`: ìƒì„±ë  ìµœëŒ€ í† í° ìˆ˜ ì œí•œ\n",
    "\n",
    "* ì‘ë‹µ ì²˜ë¦¬\n",
    "  - APIëŠ” JSON í˜•íƒœë¡œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤\n",
    "  - `response.choices[0].message.content`: ìƒì„±ëœ ë¶„ì„ í…ìŠ¤íŠ¸\n",
    "  - `response.usage`: í† í° ì‚¬ìš©ëŸ‰ ì •ë³´\n",
    "  - `response.id`: ì‘ë‹µì˜ ê³ ìœ  ì‹ë³„ì\n",
    "  - `response.model`: ì‚¬ìš©ëœ ëª¨ë¸ ì •ë³´\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- env í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½ê¸° ìœ„í•œ ì½”ë“œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CEsFc5Y1Nn428BdHsXLli4PcgsZTW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"íŒŒì´ì¬ì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ì€ `open()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—´ê³ , `read()` ë˜ëŠ” `readlines()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆì œë¥¼ í†µí•´ ì„¤ëª…ë“œë¦´ê²Œìš”.\\n\\n### 1. íŒŒì¼ ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ì½ê¸°\\n\\n```python\\nwith open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\\n    content = file.read()\\n    print(content)\\n```\\n\\n- `'r'`ì€ ì½ê¸° ëª¨ë“œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\\n- `encoding='utf-8'`ì€ íŒŒì¼ ì¸ì½”ë”©ì„ ì§€ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ, í•œê¸€ ë“± ë¬¸ìê°€ ê¹¨ì§€ì§€ ì•Šê²Œ í•˜ë ¤ë©´ ë³´í†µ UTF-8ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n- `with` ë¬¸ì„ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë‹«ì•„ì£¼ê¸° ë•Œë¬¸ì— ì•ˆì „í•©ë‹ˆë‹¤.\\n\\n### 2. íŒŒì¼ì„ í•œ ì¤„ì”© ì½ê¸°\\n\\n```python\\nwith open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\\n    for line in file:\\n        print(line.strip())  # strip()ì€ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.\\n```\\n\\n### 3. íŒŒì¼ì˜ ëª¨ë“  ì¤„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì½ê¸°\\n\\n```python\\nwith open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\\n    lines = file.readlines()\\n\\nfor line in lines:\\n    print(line.strip())\\n```\\n\\ní•„ìš”ì— ë”°ë¼ ìœ„ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757661168, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_6d7dcc9a98', usage=CompletionUsage(completion_tokens=321, prompt_tokens=32, total_tokens=353, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "====================================================================================================\n",
      "id: chatcmpl-CEsFc5Y1Nn428BdHsXLli4PcgsZTW\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: gpt-4.1-mini-2025-04-14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "text: íŒŒì´ì¬ì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ì€ `open()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—´ê³ , `read()` ë˜ëŠ” `readlines()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆì œë¥¼ í†µí•´ ì„¤ëª…ë“œë¦´ê²Œìš”.\n",
      "\n",
      "### 1. íŒŒì¼ ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ì½ê¸°\n",
      "\n",
      "```python\n",
      "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
      "    content = file.read()\n",
      "    print(content)\n",
      "```\n",
      "\n",
      "- `'r'`ì€ ì½ê¸° ëª¨ë“œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "- `encoding='utf-8'`ì€ íŒŒì¼ ì¸ì½”ë”©ì„ ì§€ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ, í•œê¸€ ë“± ë¬¸ìê°€ ê¹¨ì§€ì§€ ì•Šê²Œ í•˜ë ¤ë©´ ë³´í†µ UTF-8ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "- `with` ë¬¸ì„ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë‹«ì•„ì£¼ê¸° ë•Œë¬¸ì— ì•ˆì „í•©ë‹ˆë‹¤.\n",
      "\n",
      "### 2. íŒŒì¼ì„ í•œ ì¤„ì”© ì½ê¸°\n",
      "\n",
      "```python\n",
      "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
      "    for line in file:\n",
      "        print(line.strip())  # strip()ì€ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
      "```\n",
      "\n",
      "### 3. íŒŒì¼ì˜ ëª¨ë“  ì¤„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì½ê¸°\n",
      "\n",
      "```python\n",
      "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
      "    lines = file.readlines()\n",
      "\n",
      "for line in lines:\n",
      "    print(line.strip())\n",
      "```\n",
      "\n",
      "í•„ìš”ì— ë”°ë¼ ìœ„ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage: CompletionUsage(completion_tokens=321, prompt_tokens=32, total_tokens=353, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "# OpenAI APIë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ë°©ë²•\n",
    "from openai import OpenAI\n",
    "\n",
    "# í†µì‹ ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (.env íŒŒì¼ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ëŠ” ì£¼ì„ì„ í•´ì œí•˜ê³  api_keyë¥¼ ì§ì ‘ ì…ë ¥)\n",
    "client = OpenAI(\n",
    "    # api_key = OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "# Completion ìš”ì²­ (prompt -> completion)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        # developer ì—­í•  - ì „ë°˜ì ì¸ ë™ì‘ ë°©ì‹ ì •ì˜\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful programming assistant.\"},\n",
    "        # user ì—­í•  - ì‹¤ì œ ìš”ì²­ ë‚´ìš©\n",
    "        {\"role\": \"user\", \"content\": \"íŒŒì´ì¬ì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.\"},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)\n",
    "print(\"=\"*100)\n",
    "print(\"id:\", response.id)\n",
    "print(\"-\"*100)\n",
    "print('model:', response.model)\n",
    "print(\"-\"*100)\n",
    "print(\"text:\", response.choices[0].message.content)\n",
    "print(\"-\"*100)\n",
    "print(\"usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "íŒŒì´ì¬ì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆì§€ë§Œ, ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ì€ `open()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—´ê³ , `read()` ë˜ëŠ” `readlines()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆì œë¥¼ í†µí•´ ì„¤ëª…ë“œë¦´ê²Œìš”.\n",
       "\n",
       "### 1. íŒŒì¼ ì „ì²´ ë‚´ìš©ì„ í•œ ë²ˆì— ì½ê¸°\n",
       "\n",
       "```python\n",
       "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
       "    content = file.read()\n",
       "    print(content)\n",
       "```\n",
       "\n",
       "- `'r'`ì€ ì½ê¸° ëª¨ë“œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
       "- `encoding='utf-8'`ì€ íŒŒì¼ ì¸ì½”ë”©ì„ ì§€ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ, í•œê¸€ ë“± ë¬¸ìê°€ ê¹¨ì§€ì§€ ì•Šê²Œ í•˜ë ¤ë©´ ë³´í†µ UTF-8ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
       "- `with` ë¬¸ì„ ì‚¬ìš©í•˜ë©´ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë‹«ì•„ì£¼ê¸° ë•Œë¬¸ì— ì•ˆì „í•©ë‹ˆë‹¤.\n",
       "\n",
       "### 2. íŒŒì¼ì„ í•œ ì¤„ì”© ì½ê¸°\n",
       "\n",
       "```python\n",
       "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
       "    for line in file:\n",
       "        print(line.strip())  # strip()ì€ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
       "```\n",
       "\n",
       "### 3. íŒŒì¼ì˜ ëª¨ë“  ì¤„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì½ê¸°\n",
       "\n",
       "```python\n",
       "with open('íŒŒì¼ì´ë¦„.txt', 'r', encoding='utf-8') as file:\n",
       "    lines = file.readlines()\n",
       "\n",
       "for line in lines:\n",
       "    print(line.strip())\n",
       "```\n",
       "\n",
       "í•„ìš”ì— ë”°ë¼ ìœ„ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥ (Markdown)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### êµ¬ì¡°í™”ëœ JSON ì¶œë ¥\n",
    "\n",
    "êµ¬ì¡°í™”ëœ ì¶œë ¥ì€ ë°ì´í„° ì²˜ë¦¬ì™€ ë¶„ì„ì— ìš©ì´í•˜ë©°, API ì‘ë‹µì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "* JSON Schema ì •ì˜\n",
    "  - `response_format`ì„ í†µí•´ ì‘ë‹µì˜ í˜•ì‹ì„ JSONìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤\n",
    "  - `json_schema`ì—ì„œ ë°ì´í„° êµ¬ì¡°ì™€ ê° í•„ë“œì˜ íŠ¹ì„±ì„ ì •ì˜í•©ë‹ˆë‹¤\n",
    "    - `type`: ë°ì´í„° íƒ€ì… (string, number ë“±)\n",
    "    - `description`: ê° í•„ë“œì— ëŒ€í•œ ì„¤ëª…\n",
    "    - `required`: í•„ìˆ˜ í•„ë“œ ì§€ì •\n",
    "    - `additionalProperties`: ì¶”ê°€ ì†ì„± í—ˆìš© ì—¬ë¶€\n",
    "\n",
    "* ì •ë³´ ì¶”ì¶œ ê³¼ì •\n",
    "  - ì…ë ¥ëœ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œí™”ëœ í˜•íƒœë¡œ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "  - ì§€ì •ëœ ìŠ¤í‚¤ë§ˆì— ë§ì¶° JSON ê°ì²´ êµ¬ì„±\n",
    "  - í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ê²€ì¦\n",
    "  - ê°€ê²©ê³¼ ê°™ì€ ìˆ«ì ì •ë³´ëŠ” ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CEsFijnQ93j2PB8PTdjOLMY4fXMr5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"brand\":\"ì• í”Œ\",\"model\":\"ì•„ì´í° 15 í”„ë¡œ\",\"capacity\":\"256GB\",\"color\":\"ë¸”ë™\",\"price\":1500000,\"category\":\"ìŠ¤ë§ˆíŠ¸í°\"}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1757661174, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_daf5fcc80a', usage=CompletionUsage(completion_tokens=36, prompt_tokens=404, total_tokens=440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "====================================================================================================\n",
      "id: chatcmpl-CEsFijnQ93j2PB8PTdjOLMY4fXMr5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model: gpt-4.1-2025-04-14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "text: {\"brand\":\"ì• í”Œ\",\"model\":\"ì•„ì´í° 15 í”„ë¡œ\",\"capacity\":\"256GB\",\"color\":\"ë¸”ë™\",\"price\":1500000,\"category\":\"ìŠ¤ë§ˆíŠ¸í°\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usage: CompletionUsage(completion_tokens=36, prompt_tokens=404, total_tokens=440, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"ìƒí’ˆ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³ , ê° ì†ì„±ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì• í”Œ ì•„ì´í° 15 í”„ë¡œ 256GB (ë¸”ë™) - 1,500,000ì›\"\n",
    "        }\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"product_schema\",\n",
    "            \"description\": \"ìƒí’ˆì˜ ìƒì„¸ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê¸° ìœ„í•œ ìŠ¤í‚¤ë§ˆ\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"brand\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œì¡°ì‚¬ ë˜ëŠ” ë¸Œëœë“œ ì´ë¦„ (ì˜ˆ: ì• í”Œ, ì‚¼ì„±, LG ë“±)\"\n",
    "                    },\n",
    "                    \"model\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ëª¨ë¸ëª… ë˜ëŠ” ì‹œë¦¬ì¦ˆëª…\"\n",
    "                    },\n",
    "                    \"capacity\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì €ì¥ ìš©ëŸ‰ ë˜ëŠ” ê·œê²© (ì˜ˆ: 256GB, 512GB ë“±)\"\n",
    "                    },\n",
    "                    \"color\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ìƒ‰ìƒ\"\n",
    "                    },\n",
    "                    \"price\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ê°€ê²© (ë‹¨ìœ„: ì›)\",\n",
    "                        \"minimum\": 0\n",
    "                    },\n",
    "                    \"category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"ì œí’ˆì˜ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ìŠ¤ë§ˆíŠ¸í°, ë…¸íŠ¸ë¶ ë“±)\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"brand\", \"model\", \"price\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)\n",
    "print(\"=\"*100)\n",
    "print(\"id:\", response.id)\n",
    "print(\"-\"*100)\n",
    "print('model:', response.model)\n",
    "print(\"-\"*100)\n",
    "print(\"text:\", response.choices[0].message.content)\n",
    "print(\"-\"*100)\n",
    "print(\"usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': 'ì• í”Œ',\n",
       " 'model': 'ì•„ì´í° 15 í”„ë¡œ',\n",
       " 'capacity': '256GB',\n",
       " 'color': 'ë¸”ë™',\n",
       " 'price': 1500000,\n",
       " 'category': 'ìŠ¤ë§ˆíŠ¸í°'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(response.choices[0].message.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ì´ë¯¸ì§€ ë¶„ì„ (ë©€í‹°ëª¨ë‹¬)\n",
    "\n",
    "OpenAI APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„(ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ì„ í†µí•´ ì´ë¯¸ì§€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ê³¼ ì„¤ëª…ì„ ìì—°ì–´ë¡œ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "* ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹\n",
    "  - URL ë°©ì‹\n",
    "    - ì›¹ìƒì˜ ì´ë¯¸ì§€ URLì„ ì§ì ‘ ì „ë‹¬\n",
    "    - `image_url` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì´ë¯¸ì§€ URL ì§€ì •\n",
    "    - ì¸í„°ë„· ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‚¬ìš©\n",
    "  \n",
    "  - Base64 ì¸ì½”ë”© ë°©ì‹\n",
    "    - ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    - `encode_image()` í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©\n",
    "    - ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ `data:image/jpeg;base64,` í˜•ì‹ìœ¼ë¡œ ì „ë‹¬\n",
    "    - ë¡œì»¬ ì´ë¯¸ì§€ë‚˜ ë¹„ê³µê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì í•©\n",
    "\n",
    "* API ìš”ì²­ êµ¬ì¡°\n",
    "  - `messages` ë°°ì—´ì— ë©€í‹°ëª¨ë‹¬ ì»¨í…ì¸  í¬í•¨\n",
    "    - `type`: \"text\" ë˜ëŠ” \"image_url\"ë¡œ ì»¨í…ì¸  ìœ í˜• êµ¬ë¶„\n",
    "    - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì „ë‹¬ ê°€ëŠ¥\n",
    "    - `role`ì„ í†µí•´ ê°œë°œì/ì‚¬ìš©ì ì—­í•  ì§€ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) ì´ë¯¸ì§€ URL ì‚¬ìš©`\n",
    "\n",
    "- uv add pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpx\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_and_display_image\u001b[39m(image_url):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "async def download_and_display_image(image_url):\n",
    "    \"\"\"ì´ë¯¸ì§€ë¥¼ ë¹„ë™ê¸°ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  í‘œì‹œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        # ë¹„ë™ê¸°ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "        response = await client.get(image_url)\n",
    "        \n",
    "        # ì‘ë‹µ ìƒíƒœ í™•ì¸\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ì´ë¯¸ì§€ í¬ê¸°: {img.size}\")\n",
    "        print(f\"ì´ë¯¸ì§€ ëª¨ë“œ: {img.mode}\")\n",
    "        print(f\"ì´ë¯¸ì§€ í¬ë§·: {img.format}\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ì¶œë ¥\n",
    "        display(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "# ì´ë¯¸ì§€ URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "try:\n",
    "    img = await download_and_display_image(image_url)\n",
    "    print(\"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° í‘œì‹œ ì™„ë£Œ!\")\n",
    "except httpx.HTTPError as e:\n",
    "    print(f\"HTTP ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"ì¼ë°˜ ì—ëŸ¬ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What's in this image? Answer in í•œêµ­ì–´.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url,\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response)\n",
    "print(\"=\"*100)\n",
    "print(\"id:\", response.id)\n",
    "print(\"-\"*100)\n",
    "print('model:', response.model)\n",
    "print(\"-\"*100)\n",
    "print(\"text:\", response.choices[0].message.content)\n",
    "print(\"-\"*100)\n",
    "print(\"usage:\", response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2)  Base 64 encoded format ì‚¬ìš©`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "image_path = \"data/celltrion_report_chart.jpg\"\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¶œë ¥\n",
    "img = Image.open(image_path)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ base64 í¬ë§· ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a financial chart analyst. For any chart:\n",
    "                            1. Identify the financial metrics being displayed\n",
    "                            2. Note key price levels, support/resistance areas\n",
    "                            3. Identify significant trends and pattern formations\n",
    "                            4. Calculate relevant indicators (if visible)\n",
    "                            5. Highlight trading volume patterns\n",
    "                            6. Point out any significant market events\n",
    "                            7. Provide technical analysis insights\n",
    "                            Be specific with price levels and dates. Answer in í•œêµ­ì–´.\"\"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What does this chart show?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ì˜¤ë””ì˜¤ ì¶œë ¥\n",
    "\n",
    "\n",
    "OpenAI APIì˜ ìŒì„± ìƒì„±(Text-to-Speech) ê¸°ëŠ¥ì„ í†µí•´ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* API ìš”ì²­ ì„¤ì •\n",
    "  - `model`: \"gpt-4.1-mini-audio-preview\"ì™€ ê°™ì€ ì˜¤ë””ì˜¤ ì§€ì› ëª¨ë¸ ì‚¬ìš©\n",
    "  - `modalities`: [\"text\", \"audio\"]ë¡œ í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ ëª¨ë‘ ì¶œë ¥\n",
    "  - `audio` íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    - `voice`: ìŒì„± ì¢…ë¥˜ ì„ íƒ (ì˜ˆ: \"alloy\")\n",
    "    - `format`: ì¶œë ¥ í¬ë§· ì§€ì • (ì˜ˆ: \"wav\")\n",
    "\n",
    "* ìŒì„± ìƒì„± ê³¼ì •\n",
    "  - APIëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µê³¼ í•¨ê»˜ Base64ë¡œ ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë°˜í™˜\n",
    "  - ì‘ë‹µ êµ¬ì¡°:\n",
    "    - `completion.choices[0].message.content`: í…ìŠ¤íŠ¸ ì‘ë‹µ\n",
    "    - `completion.choices[0].message.audio.data`: Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°\n",
    "\n",
    "* ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥\n",
    "  - Base64 ë””ì½”ë”©\n",
    "    ```python\n",
    "        wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "    ```\n",
    "  - íŒŒì¼ë¡œ ì €ì¥\n",
    "    ```python\n",
    "        with open(\"sample.wav\", \"wb\") as f:\n",
    "            f.write(wav_bytes)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-audio-preview\",\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŒì„± íŒŒì¼ ì €ì¥\n",
    "import base64\n",
    "\n",
    "wav_bytes = base64.b64decode(completion.choices[0].message.audio.data)\n",
    "with open(\"sample.wav\", \"wb\") as f:\n",
    "    f.write(wav_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í† í° ì‚¬ìš©ëŸ‰\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**[ì‹¤ìŠµ 1]**: OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- `íŒíŠ¸: python-dotenv íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ì‹¤ìŠµ 2]**: ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ OpenAI API(gpt-4.1-mini)ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_simple_completion(prompt: str) -> str:\n",
    "    client = OpenAI()\n",
    "    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "print(get_simple_completion(\"What is the capital of the United States?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ë§¤ê°œë³€ìˆ˜ ìµœì í™”\n",
    "\n",
    "### âš™ï¸ í•µì‹¬ ë§¤ê°œë³€ìˆ˜ ê°€ì´ë“œ\n",
    "\n",
    "| ë§¤ê°œë³€ìˆ˜ | ë²”ìœ„ | ìš©ë„ | ì¶”ì²œê°’ |\n",
    "|---------|------|------|--------|\n",
    "| `temperature` | 0~2 | ì°½ì˜ì„± ì¡°ì ˆ | 0.3 (ì •í™•ì„±), 0.7 (ê· í˜•), 1.2 (ì°½ì˜ì„±) |\n",
    "| `top_p` | 0~1 | ì‘ë‹µ ë‹¤ì–‘ì„± | 0.9 (ê¸°ë³¸), 0.3 (ì§‘ì¤‘ì ) |\n",
    "| `max_tokens` | 1~8192+ | ìµœëŒ€ ê¸¸ì´ | ì‘ì—…ì— ë”°ë¼ ì¡°ì ˆ |\n",
    "| `frequency_penalty` | -2~2 | ë°˜ë³µ ì–µì œ | 0.3~0.6 |\n",
    "| `presence_penalty` | -2~2 | ìƒˆ ì£¼ì œ ë„ì… | 0.3~0.6 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¨ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ì •í™•í•œ ì •ë³´ ì œê³µ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ ë©”ì„œë“œë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.2,  # ë‚®ì€ ì°½ì˜ì„±\n",
    "    top_p=0.3,        # ì§‘ì¤‘ì  ì‘ë‹µ\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ì°½ì˜ì  ê¸€ì“°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ìš°ì£¼ ì •ê±°ì¥ì—ì„œì˜ í•˜ë£¨ë¥¼ ì†Œì„¤ë¡œ ì¨ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=1.1,  # ë†’ì€ ì°½ì˜ì„±\n",
    "    top_p=0.9,        # ë‹¤ì–‘í•œ í‘œí˜„\n",
    "    max_tokens=1000,\n",
    "    frequency_penalty=0.5  # ë°˜ë³µ ë°©ì§€\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ì½”ë“œ ìƒì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"ì›¹ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Python í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\"}],\n",
    "    temperature=0.4,  # ì•½ê°„ì˜ ì°½ì˜ì„±\n",
    "    max_tokens=800\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ì‹¤ìŠµ ë¬¸ì œ\n",
    "\n",
    "**ë¬¸ì œ 1: ì–¸ì–´ ë²ˆì—­ê¸° ë§Œë“¤ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(text, target_language):\n",
    "    # TODO: OpenAI APIë¥¼ ì‚¬ìš©í•´ì„œ ë²ˆì—­ í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = translator(\"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”!\", \"ì˜ì–´\")\n",
    "print(result)  # ì˜ˆìƒ ì¶œë ¥: Hello, the weather is nice today!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ë¬¸ì œ 2: ê°ì • ë¶„ì„ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    # TODO: í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì—¬ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œì„¸ìš”\n",
    "    # ë°˜í™˜ í˜•íƒœ: {\"sentiment\": \"positive/negative/neutral\", \"confidence\": 0.85}\n",
    "    # íŒíŠ¸: client.chat.completions.create()ë¥¼ ì‚¬ìš©í•˜ê³  response_formatìœ¼ë¡œ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•˜ì„¸ìš”\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = analyze_sentiment(\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ì˜ ë´¤ì–´ìš”! ì •ë§ ê¸°ì©ë‹ˆë‹¤.\")\n",
    "print(result)\n",
    "# ì˜ˆìƒ ì¶œë ¥: {'sentiment': 'positive', 'confidence': 0.95}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— ìœ ìš©í•œ ë§í¬\n",
    "- [OpenAI API ê³µì‹ ë¬¸ì„œ](https://platform.openai.com/docs)\n",
    "- [OpenAI í† í° ê³„ì‚°ê¸°](https://platform.openai.com/tokenizer)\n",
    "- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°€ì´ë“œ](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "faq_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
